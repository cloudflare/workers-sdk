import * as fs from "node:fs";
import * as path from "node:path";
import * as TOML from "@iarna/toml";
import { mockAccountId, mockApiToken } from "./helpers/mock-account-id";
import {
  createFetchResult,
  setMockRawResponse,
  setMockResponse,
  unsetAllMocks,
  unsetMockFetchKVGetValues,
} from "./helpers/mock-cfetch";
import { mockConsoleMethods } from "./helpers/mock-console";
import { mockKeyListRequest } from "./helpers/mock-kv";
import { runInTempDir } from "./helpers/run-in-tmp";
import { runWrangler } from "./helpers/run-wrangler";
import writeWranglerToml from "./helpers/write-wrangler-toml";
import type { WorkerMetadata } from "../create-worker-upload-form";
import type { KVNamespaceInfo } from "../kv";
import type { FormData, File } from "undici";

describe("publish", () => {
  beforeEach(() => {
    // @ts-expect-error we're using a very simple setTimeout mock here
    jest.spyOn(global, "setTimeout").mockImplementation((fn, _period) => {
      fn();
    });
  });
  mockAccountId();
  mockApiToken();
  runInTempDir();
  const std = mockConsoleMethods();

  afterEach(() => {
    unsetAllMocks();
    unsetMockFetchKVGetValues();
  });

  describe("environments", () => {
    it("should use legacy environments by default", async () => {
      writeWranglerToml({ env: { "some-env": {} } });
      writeWorkerSource();
      mockSubDomainRequest();
      mockUploadWorkerRequest({
        env: "some-env",
        legacyEnv: true,
      });
      await runWrangler("publish index.js --env some-env");
      expect(std.out).toMatchInlineSnapshot(`
        "Uploaded test-name-some-env (TIMINGS)
        Published test-name-some-env (TIMINGS)
          test-name-some-env.test-sub-domain.workers.dev"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
      expect(std.warn).toMatchInlineSnapshot(`""`);
    });

    describe("legacy", () => {
      it("uses the script name when no environment is specified", async () => {
        writeWranglerToml();
        writeWorkerSource();
        mockSubDomainRequest();
        mockUploadWorkerRequest({
          legacyEnv: true,
        });
        await runWrangler("publish index.js --legacy-env true");
        expect(std.out).toMatchInlineSnapshot(`
          "Uploaded test-name (TIMINGS)
          Published test-name (TIMINGS)
            test-name.test-sub-domain.workers.dev"
        `);
        expect(std.err).toMatchInlineSnapshot(`""`);
        expect(std.warn).toMatchInlineSnapshot(`""`);
      });

      it("appends the environment name when provided, and there is associated config", async () => {
        writeWranglerToml({ env: { "some-env": {} } });
        writeWorkerSource();
        mockSubDomainRequest();
        mockUploadWorkerRequest({
          env: "some-env",
          legacyEnv: true,
        });
        await runWrangler("publish index.js --env some-env --legacy-env true");
        expect(std.out).toMatchInlineSnapshot(`
          "Uploaded test-name-some-env (TIMINGS)
          Published test-name-some-env (TIMINGS)
            test-name-some-env.test-sub-domain.workers.dev"
        `);
        expect(std.err).toMatchInlineSnapshot(`""`);
        expect(std.warn).toMatchInlineSnapshot(`""`);
      });

      it("appends the environment name when provided (with a warning), if there are no configured environments", async () => {
        writeWranglerToml({});
        writeWorkerSource();
        mockSubDomainRequest();
        mockUploadWorkerRequest({
          env: "some-env",
          legacyEnv: true,
        });
        await runWrangler("publish index.js --env some-env --legacy-env true");
        expect(std.out).toMatchInlineSnapshot(`
          "Uploaded test-name-some-env (TIMINGS)
          Published test-name-some-env (TIMINGS)
            test-name-some-env.test-sub-domain.workers.dev"
        `);
        expect(std.err).toMatchInlineSnapshot(`""`);
        expect(std.warn).toMatchInlineSnapshot(`
          "Processing wrangler.toml configuration:
            - No environment found in configuration with name \\"some-env\\".
              Before using \`--env=some-env\` there should be an equivalent environment section in the configuration.

              Consider adding an environment configuration section to the wrangler.toml file:
              \`\`\`
              [env.some-env]
              \`\`\`
          "
        `);
      });

      it("should throw an error when an environment name when provided, which doesn't match those in the config", async () => {
        writeWranglerToml({ env: { "other-env": {} } });
        writeWorkerSource();
        mockSubDomainRequest();
        await expect(
          runWrangler("publish index.js --env some-env --legacy-env true")
        ).rejects.toThrowErrorMatchingInlineSnapshot(`
                "Processing wrangler.toml configuration:
                  - No environment found in configuration with name \\"some-env\\".
                    Before using \`--env=some-env\` there should be an equivalent environment section in the configuration.
                    The available configured environment names are: [\\"other-env\\"]

                    Consider adding an environment configuration section to the wrangler.toml file:
                    \`\`\`
                    [env.some-env]
                    \`\`\`
                "
              `);
      });

      it("should throw an error w/ helpful message when using --env --name", async () => {
        writeWranglerToml({ env: { "some-env": {} } });
        writeWorkerSource();
        mockSubDomainRequest();
        await runWrangler(
          "publish index.js --name voyager --env some-env --legacy-env true"
        ).catch((err) =>
          expect(err).toMatchInlineSnapshot(`
            [Error: In legacy environment mode you cannot use --name and --env together. If you want to specify a Worker name for a specific environment you can add the following to your wrangler.toml config:
                [env.some-env]
                name = "voyager"
                ]
          `)
        );
      });
    });

    describe("services", () => {
      it("uses the script name when no environment is specified", async () => {
        writeWranglerToml();
        writeWorkerSource();
        mockSubDomainRequest();
        mockUploadWorkerRequest({
          legacyEnv: false,
        });
        await runWrangler("publish index.js");
        expect(std.out).toMatchInlineSnapshot(`
          "Uploaded test-name (TIMINGS)
          Published test-name (TIMINGS)
            test-name.test-sub-domain.workers.dev"
        `);
        expect(std.err).toMatchInlineSnapshot(`""`);
        expect(std.warn).toMatchInlineSnapshot(`""`);
      });

      it("publishes as an environment when provided", async () => {
        writeWranglerToml({ env: { "some-env": {} } });
        writeWorkerSource();
        mockSubDomainRequest();
        mockUploadWorkerRequest({
          env: "some-env",
          legacyEnv: false,
        });
        await runWrangler("publish index.js --env some-env --legacy-env false");
        expect(std.out).toMatchInlineSnapshot(`
          "Uploaded test-name (some-env) (TIMINGS)
          Published test-name (some-env) (TIMINGS)
            some-env.test-name.test-sub-domain.workers.dev"
        `);
        expect(std.err).toMatchInlineSnapshot(`""`);
        expect(std.warn).toMatchInlineSnapshot(`""`);
      });
    });
  });

  it("should resolve wrangler.toml relative to the entrypoint", async () => {
    fs.mkdirSync("./some-path/worker", { recursive: true });
    fs.writeFileSync(
      "./some-path/wrangler.toml",
      TOML.stringify({
        name: "test-name",
        compatibility_date: "2022-01-12",
        vars: { xyz: 123 },
      }),
      "utf-8"
    );
    writeWorkerSource({ basePath: "./some-path/worker" });
    mockUploadWorkerRequest({
      expectedBindings: [
        {
          json: 123,
          name: "xyz",
          type: "json",
        },
      ],
      expectedCompatibilityDate: "2022-01-12",
    });
    mockSubDomainRequest();
    await runWrangler("publish ./some-path/worker/index.js");
    expect(std.out).toMatchInlineSnapshot(`
      "Uploaded test-name (TIMINGS)
      Published test-name (TIMINGS)
        test-name.test-sub-domain.workers.dev"
    `);
    expect(std.err).toMatchInlineSnapshot(`""`);
  });

  describe("routes", () => {
    it("should publish the worker to a route", async () => {
      writeWranglerToml({
        routes: ["example.com/some-route/*"],
      });
      writeWorkerSource();
      mockUpdateWorkerRequest({ enabled: false });
      mockUploadWorkerRequest({ expectedType: "esm" });
      mockPublishRoutesRequest({ routes: ["example.com/some-route/*"] });
      await runWrangler("publish ./index");
    });

    it("should publish to legacy environment specific routes", async () => {
      writeWranglerToml({
        routes: ["example.com/some-route/*"],
        env: {
          dev: {
            routes: ["dev-example.com/some-route/*"],
          },
        },
      });
      writeWorkerSource();
      mockUpdateWorkerRequest({ enabled: false, legacyEnv: true, env: "dev" });
      mockUploadWorkerRequest({
        expectedType: "esm",
        legacyEnv: true,
        env: "dev",
      });
      mockPublishRoutesRequest({
        routes: ["dev-example.com/some-route/*"],
        legacyEnv: true,
        env: "dev",
      });
      await runWrangler("publish ./index --env dev --legacy-env true");
    });

    it("services: should publish to service environment specific routes", async () => {
      writeWranglerToml({
        routes: ["example.com/some-route/*"],
        env: {
          dev: {
            routes: ["dev-example.com/some-route/*"],
          },
        },
      });
      writeWorkerSource();
      mockUpdateWorkerRequest({ enabled: false, env: "dev" });
      mockUploadWorkerRequest({
        expectedType: "esm",
        env: "dev",
      });
      mockPublishRoutesRequest({
        routes: ["dev-example.com/some-route/*"],
        env: "dev",
      });
      await runWrangler("publish ./index --env dev --legacy-env false");
    });

    it.todo("should error if it's a workers.dev route");
  });

  describe("entry-points", () => {
    it("should be able to use `index` with no extension as the entry-point (esm)", async () => {
      writeWranglerToml();
      writeWorkerSource();
      mockUploadWorkerRequest({ expectedType: "esm" });
      mockSubDomainRequest();

      await runWrangler("publish ./index");

      expect(std.out).toMatchInlineSnapshot(`
        "Uploaded test-name (TIMINGS)
        Published test-name (TIMINGS)
          test-name.test-sub-domain.workers.dev"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
    });

    it("should be able to use `index` with no extension as the entry-point (sw)", async () => {
      writeWranglerToml();
      writeWorkerSource({ type: "sw" });
      mockUploadWorkerRequest({ expectedType: "sw" });
      mockSubDomainRequest();

      await runWrangler("publish ./index");

      expect(std.out).toMatchInlineSnapshot(`
        "Uploaded test-name (TIMINGS)
        Published test-name (TIMINGS)
          test-name.test-sub-domain.workers.dev"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
    });

    it("should be able to use the `main` config as the entry-point for ESM sources", async () => {
      writeWranglerToml({ main: "./index.js" });
      writeWorkerSource();
      mockUploadWorkerRequest();
      mockSubDomainRequest();

      await runWrangler("publish");

      expect(std.out).toMatchInlineSnapshot(`
        "Uploaded test-name (TIMINGS)
        Published test-name (TIMINGS)
          test-name.test-sub-domain.workers.dev"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
    });

    it("should use `main` relative to the wrangler.toml not cwd", async () => {
      writeWranglerToml({
        main: "./foo/index.js",
      });
      writeWorkerSource({ basePath: "foo" });
      mockUploadWorkerRequest({ expectedEntry: "var foo = 100;" });
      mockSubDomainRequest();
      process.chdir("foo");
      await runWrangler("publish");

      expect(std.out).toMatchInlineSnapshot(`
        "Uploaded test-name (TIMINGS)
        Published test-name (TIMINGS)
          test-name.test-sub-domain.workers.dev"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
    });

    it('should use `build.upload.main` as an entry point, where `build.upload.dir` defaults to "./dist", and log a deprecation warning', async () => {
      writeWranglerToml({ build: { upload: { main: "./index.js" } } });
      writeWorkerSource({ basePath: "./dist" });
      mockUploadWorkerRequest();
      mockSubDomainRequest();

      await runWrangler("publish");

      expect(std.out).toMatchInlineSnapshot(`
        "Uploaded test-name (TIMINGS)
        Published test-name (TIMINGS)
          test-name.test-sub-domain.workers.dev"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
      expect(std.warn).toMatchInlineSnapshot(`
        "Processing wrangler.toml configuration:
          - DEPRECATION: \\"build.upload.main\\":
            Delete the \`build.upload.main\` and \`build.upload.dir\` fields.
            Then add the top level \`main\` field to your configuration file:
            \`\`\`
            main = \\"dist/index.js\\"
            \`\`\`"
      `);
    });

    it("should use `build.upload.main` relative to `build.upload.dir`", async () => {
      writeWranglerToml({
        build: {
          upload: {
            main: "./index.js",
            dir: "./foo",
          },
        },
      });
      writeWorkerSource({ basePath: "./foo" });
      mockUploadWorkerRequest({ expectedEntry: "var foo = 100;" });
      mockSubDomainRequest();
      process.chdir("foo");
      await runWrangler("publish");

      expect(std.out).toMatchInlineSnapshot(`
        "Uploaded test-name (TIMINGS)
        Published test-name (TIMINGS)
          test-name.test-sub-domain.workers.dev"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
      expect(std.warn).toMatchInlineSnapshot(`
        "Processing ../wrangler.toml configuration:
          - DEPRECATION: \\"build.upload.main\\":
            Delete the \`build.upload.main\` and \`build.upload.dir\` fields.
            Then add the top level \`main\` field to your configuration file:
            \`\`\`
            main = \\"foo/index.js\\"
            \`\`\`
          - DEPRECATION: \\"build.upload.dir\\":
            Use the top level \\"main\\" field or a command-line argument to specify the entry-point for the Worker."
      `);
    });

    it("should error when both `main` and `build.upload.main` are used", async () => {
      writeWranglerToml({
        main: "./index.js",
        build: {
          upload: {
            main: "./index.js",
            dir: "./foo",
          },
        },
      });
      await expect(runWrangler("publish")).rejects
        .toThrowErrorMatchingInlineSnapshot(`
              "Processing wrangler.toml configuration:
                - Don't define both the \`main\` and \`build.upload.main\` fields in your configuration.
                  They serve the same purpose: to point to the entry-point of your worker.
                  Delete the \`build.upload.main\` and \`build.upload.dir\` field from your config."
            `);
    });

    it("should be able to transpile TypeScript (esm)", async () => {
      writeWranglerToml();
      writeWorkerSource({ format: "ts" });
      mockUploadWorkerRequest({ expectedEntry: "var foo = 100;" });
      mockSubDomainRequest();
      await runWrangler("publish index.ts");

      expect(std.out).toMatchInlineSnapshot(`
        "Uploaded test-name (TIMINGS)
        Published test-name (TIMINGS)
          test-name.test-sub-domain.workers.dev"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
    });

    it("should be able to transpile TypeScript (sw)", async () => {
      writeWranglerToml();
      writeWorkerSource({ format: "ts", type: "sw" });
      mockUploadWorkerRequest({
        expectedEntry: "var foo = 100;",
        expectedType: "sw",
      });
      mockSubDomainRequest();
      await runWrangler("publish index.ts");

      expect(std.out).toMatchInlineSnapshot(`
        "Uploaded test-name (TIMINGS)
        Published test-name (TIMINGS)
          test-name.test-sub-domain.workers.dev"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
    });

    it("should add referenced text modules into the form upload", async () => {
      writeWranglerToml();
      fs.writeFileSync(
        "./index.js",
        `
import txt from './textfile.txt';
export default{
  fetch(){
    return new Response(txt);
  }
}
`
      );
      fs.writeFileSync("./textfile.txt", "Hello, World!");
      mockUploadWorkerRequest({
        expectedModules: {
          "./0a0a9f2a6772942557ab5355d76af442f8f65e01-textfile.txt":
            "Hello, World!",
        },
      });
      mockSubDomainRequest();
      await runWrangler("publish index.js");
      expect(std.out).toMatchInlineSnapshot(`
        "Uploaded test-name (TIMINGS)
        Published test-name (TIMINGS)
          test-name.test-sub-domain.workers.dev"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
    });

    it("should be able to transpile entry-points in sub-directories (esm)", async () => {
      writeWranglerToml();
      writeWorkerSource({ basePath: "./src" });
      mockUploadWorkerRequest({ expectedEntry: "var foo = 100;" });
      mockSubDomainRequest();

      await runWrangler("publish ./src/index.js");

      expect(std.out).toMatchInlineSnapshot(`
        "Uploaded test-name (TIMINGS)
        Published test-name (TIMINGS)
          test-name.test-sub-domain.workers.dev"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
    });

    it("should be able to transpile entry-points in sub-directories (sw)", async () => {
      writeWranglerToml();
      writeWorkerSource({ basePath: "./src", type: "sw" });
      mockUploadWorkerRequest({
        expectedEntry: "var foo = 100;",
        expectedType: "sw",
      });
      mockSubDomainRequest();

      await runWrangler("publish ./src/index.js");

      expect(std.out).toMatchInlineSnapshot(`
        "Uploaded test-name (TIMINGS)
        Published test-name (TIMINGS)
          test-name.test-sub-domain.workers.dev"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
    });

    it('should error if a site definition doesn\'t have a "bucket" field', async () => {
      writeWranglerToml({
        // @ts-expect-error we're intentionally setting an invalid config
        site: {},
      });
      writeWorkerSource();
      mockUploadWorkerRequest();
      mockSubDomainRequest();

      await expect(runWrangler("publish ./index.js")).rejects
        .toThrowErrorMatchingInlineSnapshot(`
              "Processing wrangler.toml configuration:
                - \\"site.bucket\\" is a required field."
            `);

      expect(std.out).toMatchInlineSnapshot(`""`);
      expect(std.err).toMatchInlineSnapshot(`
        "Processing wrangler.toml configuration:
          - \\"site.bucket\\" is a required field.

        [32m%s[0m If you think this is a bug then please create an issue at https://github.com/cloudflare/wrangler2/issues/new."
      `);
      expect(std.warn).toMatchInlineSnapshot(`""`);
    });

    it("should error if there is a `site.entry-point` configuration", async () => {
      const assets = [
        { filePath: "assets/file-1.txt", content: "Content of file-1" },
        { filePath: "assets/file-2.txt", content: "Content of file-2" },
      ];
      const kvNamespace = {
        title: "__test-name-workers_sites_assets",
        id: "__test-name-workers_sites_assets-id",
      };

      writeWranglerToml({
        site: {
          "entry-point": "./index.js",
          bucket: "assets",
        },
      });
      writeWorkerSource();
      writeAssets(assets);
      mockUploadWorkerRequest();
      mockSubDomainRequest();
      mockListKVNamespacesRequest(kvNamespace);
      mockKeyListRequest(kvNamespace.id, []);
      mockUploadAssetsToKVRequest(kvNamespace.id, assets);

      await expect(runWrangler("publish ./index.js")).rejects
        .toThrowErrorMatchingInlineSnapshot(`
              "Processing wrangler.toml configuration:
                - DEPRECATION: \\"site.entry-point\\":
                  The \`site.entry-point\` config field is no longer used.
                  The entry-point should be specified via the command line or the \`main\` config field."
            `);

      expect(std.out).toMatchInlineSnapshot(`""`);
      expect(std.err).toMatchInlineSnapshot(`
        "Processing wrangler.toml configuration:
          - DEPRECATION: \\"site.entry-point\\":
            The \`site.entry-point\` config field is no longer used.
            The entry-point should be specified via the command line or the \`main\` config field.

        [32m%s[0m If you think this is a bug then please create an issue at https://github.com/cloudflare/wrangler2/issues/new."
      `);
      expect(std.warn).toMatchInlineSnapshot(`
        "Processing wrangler.toml configuration:
          - Unexpected fields found in site field: \\"entry-point\\""
      `);
    });

    it("should error if there is no entry-point specified", async () => {
      writeWranglerToml();
      writeWorkerSource();
      mockUploadWorkerRequest();
      mockSubDomainRequest();
      await expect(
        runWrangler("publish")
      ).rejects.toThrowErrorMatchingInlineSnapshot(
        `"Missing entry-point: The entry-point should be specified via the command line (e.g. \`wrangler publish path/to/script\`) or the \`main\` config field."`
      );

      expect(std.out).toMatchInlineSnapshot(`""`);
      expect(std.err).toMatchInlineSnapshot(`
        "Missing entry-point: The entry-point should be specified via the command line (e.g. \`wrangler publish path/to/script\`) or the \`main\` config field.

        [32m%s[0m If you think this is a bug then please create an issue at https://github.com/cloudflare/wrangler2/issues/new."
      `);
    });
  });

  describe("asset upload", () => {
    it("should upload all the files in the directory specified by `config.site.bucket`", async () => {
      const assets = [
        { filePath: "assets/file-1.txt", content: "Content of file-1" },
        { filePath: "assets/file-2.txt", content: "Content of file-2" },
      ];
      const kvNamespace = {
        title: "__test-name-workers_sites_assets",
        id: "__test-name-workers_sites_assets-id",
      };
      writeWranglerToml({
        main: "./index.js",
        site: {
          bucket: "assets",
        },
      });
      writeWorkerSource();
      writeAssets(assets);
      mockUploadWorkerRequest();
      mockSubDomainRequest();
      mockListKVNamespacesRequest(kvNamespace);
      mockKeyListRequest(kvNamespace.id, []);
      mockUploadAssetsToKVRequest(kvNamespace.id, assets);
      await runWrangler("publish");

      expect(std.out).toMatchInlineSnapshot(`
        "reading assets/file-1.txt...
        uploading as assets/file-1.2ca234f380.txt...
        reading assets/file-2.txt...
        uploading as assets/file-2.5938485188.txt...
        ↗️  Done syncing assets
        Uploaded test-name (TIMINGS)
        Published test-name (TIMINGS)
          test-name.test-sub-domain.workers.dev"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
    });

    it("when using a service worker type, it should add an asset manifest as a text_blob, and bind to a namespace", async () => {
      const assets = [
        { filePath: "assets/file-1.txt", content: "Content of file-1" },
        { filePath: "assets/file-2.txt", content: "Content of file-2" },
      ];
      const kvNamespace = {
        title: "__test-name-workers_sites_assets",
        id: "__test-name-workers_sites_assets-id",
      };
      writeWranglerToml({
        main: "./index.js",
        site: {
          bucket: "assets",
        },
      });
      writeWorkerSource({ type: "sw" });
      writeAssets(assets);
      mockUploadWorkerRequest({
        expectedType: "sw",
        expectedModules: {
          __STATIC_CONTENT_MANIFEST:
            '{"file-1.txt":"assets/file-1.2ca234f380.txt","file-2.txt":"assets/file-2.5938485188.txt"}',
        },
        expectedBindings: [
          {
            name: "__STATIC_CONTENT",
            namespace_id: "__test-name-workers_sites_assets-id",
            type: "kv_namespace",
          },
          {
            name: "__STATIC_CONTENT_MANIFEST",
            part: "__STATIC_CONTENT_MANIFEST",
            type: "text_blob",
          },
        ],
      });
      mockSubDomainRequest();
      mockListKVNamespacesRequest(kvNamespace);
      mockKeyListRequest(kvNamespace.id, []);
      mockUploadAssetsToKVRequest(kvNamespace.id, assets);

      await runWrangler("publish");

      expect(std.out).toMatchInlineSnapshot(`
        "reading assets/file-1.txt...
        uploading as assets/file-1.2ca234f380.txt...
        reading assets/file-2.txt...
        uploading as assets/file-2.5938485188.txt...
        ↗️  Done syncing assets
        Uploaded test-name (TIMINGS)
        Published test-name (TIMINGS)
          test-name.test-sub-domain.workers.dev"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
    });

    it("when using a module worker type, it should add an asset manifest module, and bind to a namespace", async () => {
      const assets = [
        { filePath: "assets/file-1.txt", content: "Content of file-1" },
        { filePath: "assets/file-2.txt", content: "Content of file-2" },
      ];
      const kvNamespace = {
        title: "__test-name-workers_sites_assets",
        id: "__test-name-workers_sites_assets-id",
      };
      writeWranglerToml({
        main: "./index.js",
        site: {
          bucket: "assets",
        },
      });
      writeWorkerSource({ type: "esm" });
      writeAssets(assets);
      mockUploadWorkerRequest({
        expectedBindings: [
          {
            name: "__STATIC_CONTENT",
            namespace_id: "__test-name-workers_sites_assets-id",
            type: "kv_namespace",
          },
        ],
        expectedModules: {
          __STATIC_CONTENT_MANIFEST:
            '{"file-1.txt":"assets/file-1.2ca234f380.txt","file-2.txt":"assets/file-2.5938485188.txt"}',
        },
      });
      mockSubDomainRequest();
      mockListKVNamespacesRequest(kvNamespace);
      mockKeyListRequest(kvNamespace.id, []);
      mockUploadAssetsToKVRequest(kvNamespace.id, assets);

      await runWrangler("publish");

      expect(std.out).toMatchInlineSnapshot(`
        "reading assets/file-1.txt...
        uploading as assets/file-1.2ca234f380.txt...
        reading assets/file-2.txt...
        uploading as assets/file-2.5938485188.txt...
        ↗️  Done syncing assets
        Uploaded test-name (TIMINGS)
        Published test-name (TIMINGS)
          test-name.test-sub-domain.workers.dev"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
    });

    it("should make environment specific kv namespace for assets, even for service envs", async () => {
      // This is the same test as the one before this, but with an env arg
      const assets = [
        { filePath: "assets/file-1.txt", content: "Content of file-1" },
        { filePath: "assets/file-2.txt", content: "Content of file-2" },
      ];
      const kvNamespace = {
        title: "__test-name-some-env-workers_sites_assets",
        id: "__test-name-some-env-workers_sites_assets-id",
      };
      writeWranglerToml({
        main: "./index.js",
        site: {
          bucket: "assets",
        },
        env: { "some-env": {} },
      });
      writeWorkerSource();
      writeAssets(assets);
      mockUploadWorkerRequest({
        env: "some-env",
        expectedBindings: [
          {
            name: "__STATIC_CONTENT",
            namespace_id: "__test-name-some-env-workers_sites_assets-id",
            type: "kv_namespace",
          },
        ],
      });
      mockSubDomainRequest();
      mockListKVNamespacesRequest(kvNamespace);
      mockKeyListRequest(kvNamespace.id, []);
      mockUploadAssetsToKVRequest(kvNamespace.id, assets);
      await runWrangler("publish --env some-env --legacy-env false");

      expect(std.out).toMatchInlineSnapshot(`
        "reading assets/file-1.txt...
        uploading as assets/file-1.2ca234f380.txt...
        reading assets/file-2.txt...
        uploading as assets/file-2.5938485188.txt...
        ↗️  Done syncing assets
        Uploaded test-name (some-env) (TIMINGS)
        Published test-name (some-env) (TIMINGS)
          some-env.test-name.test-sub-domain.workers.dev"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
    });

    it("should make environment specific kv namespace for assets, even for legacy envs", async () => {
      // And this is the same test as the one before this, but with legacyEnv:true
      const assets = [
        { filePath: "assets/file-1.txt", content: "Content of file-1" },
        { filePath: "assets/file-2.txt", content: "Content of file-2" },
      ];
      const kvNamespace = {
        title: "__test-name-some-env-workers_sites_assets",
        id: "__test-name-some-env-workers_sites_assets-id",
      };
      writeWranglerToml({
        main: "./index.js",
        site: {
          bucket: "assets",
        },
        env: { "some-env": {} },
      });
      writeWorkerSource();
      writeAssets(assets);
      mockUploadWorkerRequest({
        legacyEnv: true,
        env: "some-env",
        expectedBindings: [
          {
            name: "__STATIC_CONTENT",
            namespace_id: "__test-name-some-env-workers_sites_assets-id",
            type: "kv_namespace",
          },
        ],
      });
      mockSubDomainRequest();
      mockListKVNamespacesRequest(kvNamespace);
      mockKeyListRequest(kvNamespace.id, []);
      mockUploadAssetsToKVRequest(kvNamespace.id, assets);
      await runWrangler("publish --env some-env --legacy-env true");

      expect(std.out).toMatchInlineSnapshot(`
        "reading assets/file-1.txt...
        uploading as assets/file-1.2ca234f380.txt...
        reading assets/file-2.txt...
        uploading as assets/file-2.5938485188.txt...
        ↗️  Done syncing assets
        Uploaded test-name-some-env (TIMINGS)
        Published test-name-some-env (TIMINGS)
          test-name-some-env.test-sub-domain.workers.dev"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
    });

    it("should only upload files that are not already in the KV namespace", async () => {
      const assets = [
        { filePath: "assets/file-1.txt", content: "Content of file-1" },
        { filePath: "assets/file-2.txt", content: "Content of file-2" },
      ];
      const kvNamespace = {
        title: "__test-name-workers_sites_assets",
        id: "__test-name-workers_sites_assets-id",
      };
      writeWranglerToml({
        main: "./index.js",
        site: {
          bucket: "assets",
        },
      });
      writeWorkerSource();
      writeAssets(assets);
      mockUploadWorkerRequest();
      mockSubDomainRequest();
      mockListKVNamespacesRequest(kvNamespace);
      // Put file-1 in the KV namespace
      mockKeyListRequest(kvNamespace.id, [
        { name: "assets/file-1.2ca234f380.txt" },
      ]);
      // Check we do not upload file-1
      mockUploadAssetsToKVRequest(
        kvNamespace.id,
        assets.filter((a) => a.filePath !== "assets/file-1.txt")
      );
      await runWrangler("publish");

      expect(std.out).toMatchInlineSnapshot(`
        "reading assets/file-1.txt...
        skipping - already uploaded
        reading assets/file-2.txt...
        uploading as assets/file-2.5938485188.txt...
        ↗️  Done syncing assets
        Uploaded test-name (TIMINGS)
        Published test-name (TIMINGS)
          test-name.test-sub-domain.workers.dev"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
    });

    it("should only upload files that match the `site-include` arg", async () => {
      const assets = [
        { filePath: "assets/file-1.txt", content: "Content of file-1" },
        { filePath: "assets/file-2.txt", content: "Content of file-2" },
      ];
      const kvNamespace = {
        title: "__test-name-workers_sites_assets",
        id: "__test-name-workers_sites_assets-id",
      };
      writeWranglerToml({
        main: "./index.js",
        site: {
          bucket: "assets",
        },
      });
      writeWorkerSource();
      writeAssets(assets);
      mockUploadWorkerRequest();
      mockSubDomainRequest();
      mockListKVNamespacesRequest(kvNamespace);
      mockKeyListRequest(kvNamespace.id, []);
      // Check we only upload file-1
      mockUploadAssetsToKVRequest(
        kvNamespace.id,
        assets.filter((a) => a.filePath === "assets/file-1.txt")
      );
      await runWrangler("publish --site-include file-1.txt");

      expect(std.out).toMatchInlineSnapshot(`
        "reading assets/file-1.txt...
        uploading as assets/file-1.2ca234f380.txt...
        ↗️  Done syncing assets
        Uploaded test-name (TIMINGS)
        Published test-name (TIMINGS)
          test-name.test-sub-domain.workers.dev"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
    });

    it("should not upload files that match the `site-exclude` arg", async () => {
      const assets = [
        { filePath: "assets/file-1.txt", content: "Content of file-1" },
        { filePath: "assets/file-2.txt", content: "Content of file-2" },
      ];
      const kvNamespace = {
        title: "__test-name-workers_sites_assets",
        id: "__test-name-workers_sites_assets-id",
      };
      writeWranglerToml({
        main: "./index.js",
        site: {
          bucket: "assets",
        },
      });
      writeWorkerSource();
      writeAssets(assets);
      mockUploadWorkerRequest();
      mockSubDomainRequest();
      mockListKVNamespacesRequest(kvNamespace);
      mockKeyListRequest(kvNamespace.id, []);
      // Check we only upload file-1
      mockUploadAssetsToKVRequest(
        kvNamespace.id,
        assets.filter((a) => a.filePath === "assets/file-1.txt")
      );
      await runWrangler("publish --site-exclude file-2.txt");

      expect(std.out).toMatchInlineSnapshot(`
        "reading assets/file-1.txt...
        uploading as assets/file-1.2ca234f380.txt...
        ↗️  Done syncing assets
        Uploaded test-name (TIMINGS)
        Published test-name (TIMINGS)
          test-name.test-sub-domain.workers.dev"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
    });

    it("should only upload files that match the `site.include` config", async () => {
      const assets = [
        { filePath: "assets/file-1.txt", content: "Content of file-1" },
        { filePath: "assets/file-2.txt", content: "Content of file-2" },
      ];
      const kvNamespace = {
        title: "__test-name-workers_sites_assets",
        id: "__test-name-workers_sites_assets-id",
      };
      writeWranglerToml({
        main: "./index.js",
        site: {
          bucket: "assets",
          include: ["file-1.txt"],
        },
      });
      writeWorkerSource();
      writeAssets(assets);
      mockUploadWorkerRequest();
      mockSubDomainRequest();
      mockListKVNamespacesRequest(kvNamespace);
      mockKeyListRequest(kvNamespace.id, []);
      // Check we only upload file-1
      mockUploadAssetsToKVRequest(
        kvNamespace.id,
        assets.filter((a) => a.filePath === "assets/file-1.txt")
      );
      await runWrangler("publish");

      expect(std.out).toMatchInlineSnapshot(`
        "reading assets/file-1.txt...
        uploading as assets/file-1.2ca234f380.txt...
        ↗️  Done syncing assets
        Uploaded test-name (TIMINGS)
        Published test-name (TIMINGS)
          test-name.test-sub-domain.workers.dev"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
    });

    it("should not upload files that match the `site.exclude` config", async () => {
      const assets = [
        { filePath: "assets/file-1.txt", content: "Content of file-1" },
        { filePath: "assets/file-2.txt", content: "Content of file-2" },
      ];
      const kvNamespace = {
        title: "__test-name-workers_sites_assets",
        id: "__test-name-workers_sites_assets-id",
      };
      writeWranglerToml({
        main: "./index.js",
        site: {
          bucket: "assets",
          exclude: ["file-2.txt"],
        },
      });
      writeWorkerSource();
      writeAssets(assets);
      mockUploadWorkerRequest();
      mockSubDomainRequest();
      mockListKVNamespacesRequest(kvNamespace);
      mockKeyListRequest(kvNamespace.id, []);
      // Check we only upload file-1
      mockUploadAssetsToKVRequest(
        kvNamespace.id,
        assets.filter((a) => a.filePath === "assets/file-1.txt")
      );
      await runWrangler("publish");

      expect(std.out).toMatchInlineSnapshot(`
        "reading assets/file-1.txt...
        uploading as assets/file-1.2ca234f380.txt...
        ↗️  Done syncing assets
        Uploaded test-name (TIMINGS)
        Published test-name (TIMINGS)
          test-name.test-sub-domain.workers.dev"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
    });

    it("should use `site-include` arg over `site.include` config", async () => {
      const assets = [
        { filePath: "assets/file-1.txt", content: "Content of file-1" },
        { filePath: "assets/file-2.txt", content: "Content of file-2" },
      ];
      const kvNamespace = {
        title: "__test-name-workers_sites_assets",
        id: "__test-name-workers_sites_assets-id",
      };
      writeWranglerToml({
        main: "./index.js",
        site: {
          bucket: "assets",
          include: ["file-2.txt"],
        },
      });
      writeWorkerSource();
      writeAssets(assets);
      mockUploadWorkerRequest();
      mockSubDomainRequest();
      mockListKVNamespacesRequest(kvNamespace);
      mockKeyListRequest(kvNamespace.id, []);
      // Check we only upload file-1
      mockUploadAssetsToKVRequest(
        kvNamespace.id,
        assets.filter((a) => a.filePath === "assets/file-1.txt")
      );
      await runWrangler("publish --site-include file-1.txt");

      expect(std.out).toMatchInlineSnapshot(`
        "reading assets/file-1.txt...
        uploading as assets/file-1.2ca234f380.txt...
        ↗️  Done syncing assets
        Uploaded test-name (TIMINGS)
        Published test-name (TIMINGS)
          test-name.test-sub-domain.workers.dev"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
    });

    it("should use `site-exclude` arg over `site.exclude` config", async () => {
      const assets = [
        { filePath: "assets/file-1.txt", content: "Content of file-1" },
        { filePath: "assets/file-2.txt", content: "Content of file-2" },
      ];
      const kvNamespace = {
        title: "__test-name-workers_sites_assets",
        id: "__test-name-workers_sites_assets-id",
      };
      writeWranglerToml({
        main: "./index.js",
        site: {
          bucket: "assets",
          exclude: ["assets/file-1.txt"],
        },
      });
      writeWorkerSource();
      writeAssets(assets);
      mockUploadWorkerRequest();
      mockSubDomainRequest();
      mockListKVNamespacesRequest(kvNamespace);
      mockKeyListRequest(kvNamespace.id, []);
      // Check we only upload file-1
      mockUploadAssetsToKVRequest(
        kvNamespace.id,
        assets.filter((a) => a.filePath.endsWith("assets/file-1.txt"))
      );
      await runWrangler("publish --site-exclude file-2.txt");

      expect(std.out).toMatchInlineSnapshot(`
        "reading assets/file-1.txt...
        uploading as assets/file-1.2ca234f380.txt...
        ↗️  Done syncing assets
        Uploaded test-name (TIMINGS)
        Published test-name (TIMINGS)
          test-name.test-sub-domain.workers.dev"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
    });

    it("should walk directories except node_modules", async () => {
      const assets = [
        {
          filePath: "assets/directory-1/file-1.txt",
          content: "Content of file-1",
        },
        {
          filePath: "assets/node_modules/file-2.txt",
          content: "Content of file-2",
        },
      ];
      const kvNamespace = {
        title: "__test-name-workers_sites_assets",
        id: "__test-name-workers_sites_assets-id",
      };
      writeWranglerToml({
        main: "./index.js",
        site: {
          bucket: "assets",
        },
      });
      writeWorkerSource();
      writeAssets(assets);
      mockUploadWorkerRequest();
      mockSubDomainRequest();
      mockListKVNamespacesRequest(kvNamespace);
      mockKeyListRequest(kvNamespace.id, []);
      // Only expect file-1 to be uploaded
      mockUploadAssetsToKVRequest(kvNamespace.id, assets.slice(0, 1));
      await runWrangler("publish");

      expect(std.out).toMatchInlineSnapshot(`
        "reading assets/directory-1/file-1.txt...
        uploading as assets/directory-1/file-1.2ca234f380.txt...
        ↗️  Done syncing assets
        Uploaded test-name (TIMINGS)
        Published test-name (TIMINGS)
          test-name.test-sub-domain.workers.dev"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
    });

    it("should skip hidden files and directories except `.well-known`", async () => {
      const assets = [
        {
          filePath: "assets/.hidden-file.txt",
          content: "Content of hidden-file",
        },
        {
          filePath: "assets/.hidden/file-1.txt",
          content: "Content of file-1",
        },
        {
          filePath: "assets/.well-known/file-2.txt",
          content: "Content of file-2",
        },
      ];
      const kvNamespace = {
        title: "__test-name-workers_sites_assets",
        id: "__test-name-workers_sites_assets-id",
      };
      writeWranglerToml({
        main: "./index.js",
        site: {
          bucket: "assets",
        },
      });
      writeWorkerSource();
      writeAssets(assets);
      mockUploadWorkerRequest();
      mockSubDomainRequest();
      mockListKVNamespacesRequest(kvNamespace);
      mockKeyListRequest(kvNamespace.id, []);
      // Only expect file-2 to be uploaded
      mockUploadAssetsToKVRequest(kvNamespace.id, assets.slice(2));
      await runWrangler("publish");

      expect(std.out).toMatchInlineSnapshot(`
        "reading assets/.well-known/file-2.txt...
        uploading as assets/.well-known/file-2.5938485188.txt...
        ↗️  Done syncing assets
        Uploaded test-name (TIMINGS)
        Published test-name (TIMINGS)
          test-name.test-sub-domain.workers.dev"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
    });

    it("should error if the asset is over 25Mb", async () => {
      const assets = [
        {
          filePath: "assets/large-file.txt",
          // This file is greater than 25MiB when base64 encoded but small enough to be uploaded.
          content: "X".repeat(25 * 1024 * 1024 * 0.8 + 1),
        },
        {
          filePath: "assets/too-large-file.txt",
          content: "X".repeat(25 * 1024 * 1024 + 1),
        },
      ];
      const kvNamespace = {
        title: "__test-name-workers_sites_assets",
        id: "__test-name-workers_sites_assets-id",
      };
      writeWranglerToml({
        main: "./index.js",
        site: {
          bucket: "assets",
          exclude: ["assets/file-1.txt"],
        },
      });
      writeWorkerSource();
      writeAssets(assets);
      mockUploadWorkerRequest();
      mockSubDomainRequest();
      mockListKVNamespacesRequest(kvNamespace);
      mockKeyListRequest(kvNamespace.id, []);

      await expect(
        runWrangler("publish")
      ).rejects.toThrowErrorMatchingInlineSnapshot(
        `"File assets/too-large-file.txt is too big, it should be under 25 MiB. See https://developers.cloudflare.com/workers/platform/limits#kv-limits"`
      );

      expect(std.out).toMatchInlineSnapshot(`
        "reading assets/large-file.txt...
        uploading as assets/large-file.0ea0637a45.txt..."
      `);
      expect(std.err).toMatchInlineSnapshot(`
        "File assets/too-large-file.txt is too big, it should be under 25 MiB. See https://developers.cloudflare.com/workers/platform/limits#kv-limits

        [32m%s[0m If you think this is a bug then please create an issue at https://github.com/cloudflare/wrangler2/issues/new."
      `);
    });

    it("should error if the asset key is over 512 characters", async () => {
      const longFilePathAsset = {
        filePath: "assets/" + "folder/".repeat(100) + "file.txt",
        content: "content of file",
      };
      const kvNamespace = {
        title: "__test-name-workers_sites_assets",
        id: "__test-name-workers_sites_assets-id",
      };
      writeWranglerToml({
        main: "./index.js",
        site: {
          bucket: "assets",
        },
      });
      writeWorkerSource();
      writeAssets([longFilePathAsset]);
      mockUploadWorkerRequest();
      mockSubDomainRequest();
      mockListKVNamespacesRequest(kvNamespace);
      mockKeyListRequest(kvNamespace.id, []);

      await expect(
        runWrangler("publish")
      ).rejects.toThrowErrorMatchingInlineSnapshot(
        `"The asset path key \\"assets/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/file.3da0d0cd12.txt\\" exceeds the maximum key size limit of 512. See https://developers.cloudflare.com/workers/platform/limits#kv-limits\\","`
      );

      expect(std.out).toMatchInlineSnapshot(
        `"reading assets/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/file.txt..."`
      );
      expect(std.err).toMatchInlineSnapshot(`
        "The asset path key \\"assets/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/folder/file.3da0d0cd12.txt\\" exceeds the maximum key size limit of 512. See https://developers.cloudflare.com/workers/platform/limits#kv-limits\\",

        [32m%s[0m If you think this is a bug then please create an issue at https://github.com/cloudflare/wrangler2/issues/new."
      `);
    });

    it("should delete uploaded assets that aren't included anymore", async () => {
      const assets = [
        { filePath: "assets/file-1.txt", content: "Content of file-1" },
        { filePath: "assets/file-2.txt", content: "Content of file-2" },
      ];
      const kvNamespace = {
        title: "__test-name-workers_sites_assets",
        id: "__test-name-workers_sites_assets-id",
      };
      writeWranglerToml({
        main: "./index.js",
        site: {
          bucket: "assets",
        },
      });
      writeWorkerSource();
      writeAssets(assets);
      mockUploadWorkerRequest();
      mockSubDomainRequest();
      mockListKVNamespacesRequest(kvNamespace);
      mockKeyListRequest(kvNamespace.id, [
        // Put file-1 in the KV namespace
        { name: "assets/file-1.2ca234f380.txt" },
        // As well as a couple from a previous upload
        { name: "assets/file-3.somehash.txt" },
        { name: "assets/file-4.anotherhash.txt" },
      ]);

      // we upload only file-1.txt
      mockUploadAssetsToKVRequest(kvNamespace.id, [
        ...assets.filter((a) => a.filePath !== "assets/file-1.txt"),
      ]);

      // and mark file-3 and file-4 for deletion
      mockDeleteUnusedAssetsRequest(kvNamespace.id, [
        "assets/file-3.somehash.txt",
        "assets/file-4.anotherhash.txt",
      ]);

      await runWrangler("publish");

      expect(std.out).toMatchInlineSnapshot(`
        "reading assets/file-1.txt...
        skipping - already uploaded
        reading assets/file-2.txt...
        uploading as assets/file-2.5938485188.txt...
        deleting assets/file-3.somehash.txt from the asset store...
        deleting assets/file-4.anotherhash.txt from the asset store...
        ↗️  Done syncing assets
        Uploaded test-name (TIMINGS)
        Published test-name (TIMINGS)
          test-name.test-sub-domain.workers.dev"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
    });
  });

  describe("workers_dev setting", () => {
    it("should publish to a workers.dev domain if workers_dev is undefined", async () => {
      writeWranglerToml();
      writeWorkerSource();
      mockUploadWorkerRequest();
      mockSubDomainRequest();

      await runWrangler("publish ./index");

      expect(std.out).toMatchInlineSnapshot(`
        "Uploaded test-name (TIMINGS)
        Published test-name (TIMINGS)
          test-name.test-sub-domain.workers.dev"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
    });

    it("should publish to the workers.dev domain if workers_dev is `true`", async () => {
      writeWranglerToml({
        workers_dev: true,
      });
      writeWorkerSource();
      mockUploadWorkerRequest();
      mockSubDomainRequest();

      await runWrangler("publish ./index");

      expect(std.out).toMatchInlineSnapshot(`
        "Uploaded test-name (TIMINGS)
        Published test-name (TIMINGS)
          test-name.test-sub-domain.workers.dev"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
    });

    it("should disable the workers.dev domain if workers_dev is `false`", async () => {
      writeWranglerToml({
        workers_dev: false,
      });
      writeWorkerSource();
      mockUploadWorkerRequest();
      mockUpdateWorkerRequest({ enabled: false });

      await runWrangler("publish ./index");

      expect(std.out).toMatchInlineSnapshot(`
        "Uploaded test-name (TIMINGS)
        No publish targets for test-name (TIMINGS)"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
    });

    it("should disable the workers.dev domain if workers_dev is undefined but overwritten to `false` in environment", async () => {
      writeWranglerToml({
        env: {
          dev: {
            workers_dev: false,
          },
        },
      });
      writeWorkerSource();
      mockUploadWorkerRequest({
        env: "dev",
      });
      mockUpdateWorkerRequest({ enabled: false, env: "dev" });

      await runWrangler("publish ./index --env dev --legacy-env false");

      expect(std.out).toMatchInlineSnapshot(`
        "Uploaded test-name (dev) (TIMINGS)
        No publish targets for test-name (dev) (TIMINGS)"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
    });

    it("should disable the workers.dev domain if workers_dev is `true` but overwritten to `false` in environment", async () => {
      writeWranglerToml({
        workers_dev: true,
        env: {
          dev: {
            workers_dev: false,
          },
        },
      });
      writeWorkerSource();
      mockUploadWorkerRequest({
        env: "dev",
      });
      mockUpdateWorkerRequest({ enabled: false, env: "dev" });

      await runWrangler("publish ./index --env dev --legacy-env false");

      expect(std.out).toMatchInlineSnapshot(`
        "Uploaded test-name (dev) (TIMINGS)
        No publish targets for test-name (dev) (TIMINGS)"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
    });

    it("should publish to a workers.dev domain if workers_dev is undefined but overwritten to `true` in environment", async () => {
      writeWranglerToml({
        env: {
          dev: {
            workers_dev: true,
          },
        },
      });
      writeWorkerSource();
      mockUploadWorkerRequest({
        env: "dev",
      });
      mockSubDomainRequest();
      mockUpdateWorkerRequest({ enabled: true, env: "dev" });

      await runWrangler("publish ./index --env dev --legacy-env false");

      expect(std.out).toMatchInlineSnapshot(`
        "Uploaded test-name (dev) (TIMINGS)
        Published test-name (dev) (TIMINGS)
          dev.test-name.test-sub-domain.workers.dev"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
    });

    it("should publish to a workers.dev domain if workers_dev is `false` but overwritten to `true` in environment", async () => {
      writeWranglerToml({
        workers_dev: false,
        env: {
          dev: {
            workers_dev: true,
          },
        },
      });
      writeWorkerSource();
      mockUploadWorkerRequest({
        env: "dev",
      });
      mockSubDomainRequest();
      mockUpdateWorkerRequest({ enabled: true, env: "dev" });

      await runWrangler("publish ./index --env dev --legacy-env false");

      expect(std.out).toMatchInlineSnapshot(`
        "Uploaded test-name (dev) (TIMINGS)
        Published test-name (dev) (TIMINGS)
          dev.test-name.test-sub-domain.workers.dev"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
    });

    it("should use the global compatibility_date and compatibility_flags if they are not overwritten by the environment", async () => {
      writeWranglerToml({
        compatibility_date: "2022-01-12",
        compatibility_flags: ["no_global_navigator"],
        env: {
          dev: {},
        },
      });
      writeWorkerSource();
      mockUploadWorkerRequest({
        env: "dev",
        expectedCompatibilityDate: "2022-01-12",
        expectedCompatibilityFlags: ["no_global_navigator"],
      });
      mockSubDomainRequest();
      mockUpdateWorkerRequest({ enabled: true, env: "dev" });

      await runWrangler("publish ./index --env dev --legacy-env false");

      expect(std.out).toMatchInlineSnapshot(`
        "Uploaded test-name (dev) (TIMINGS)
        Published test-name (dev) (TIMINGS)
          dev.test-name.test-sub-domain.workers.dev"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
    });

    it("should use the environment specific compatibility_date and compatibility_flags", async () => {
      writeWranglerToml({
        compatibility_date: "2022-01-12",
        compatibility_flags: ["no_global_navigator"],
        env: {
          dev: {
            compatibility_date: "2022-01-13",
            compatibility_flags: ["global_navigator"],
          },
        },
      });
      writeWorkerSource();
      mockUploadWorkerRequest({
        env: "dev",
        expectedCompatibilityDate: "2022-01-13",
        expectedCompatibilityFlags: ["global_navigator"],
      });
      mockSubDomainRequest();
      mockUpdateWorkerRequest({ enabled: true, env: "dev" });

      await runWrangler("publish ./index --env dev --legacy-env false");

      expect(std.out).toMatchInlineSnapshot(`
        "Uploaded test-name (dev) (TIMINGS)
        Published test-name (dev) (TIMINGS)
          dev.test-name.test-sub-domain.workers.dev"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
    });

    it("should use the command line --compatibility-date and --compatibility-flags if they are specified", async () => {
      writeWranglerToml({
        compatibility_date: "2022-01-12",
        compatibility_flags: ["no_global_navigator"],
        env: {
          dev: {
            compatibility_date: "2022-01-13",
            compatibility_flags: ["global_navigator"],
          },
        },
      });
      writeWorkerSource();
      mockUploadWorkerRequest({
        env: "dev",
        expectedCompatibilityDate: "2022-01-14",
        expectedCompatibilityFlags: ["url_standard"],
      });
      mockSubDomainRequest();
      mockUpdateWorkerRequest({ enabled: true, env: "dev" });

      await runWrangler(
        "publish ./index --env dev --legacy-env false --compatibility-date 2022-01-14 --compatibility-flags url_standard"
      );

      expect(std.out).toMatchInlineSnapshot(`
        "Uploaded test-name (dev) (TIMINGS)
        Published test-name (dev) (TIMINGS)
          dev.test-name.test-sub-domain.workers.dev"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
    });

    it("should enable the workers.dev domain if workers_dev is undefined and subdomain is not already available", async () => {
      writeWranglerToml();
      writeWorkerSource();
      mockUploadWorkerRequest({ available_on_subdomain: false });
      mockSubDomainRequest();
      mockUpdateWorkerRequest({ enabled: true });

      await runWrangler("publish ./index");

      expect(std.out).toMatchInlineSnapshot(`
        "Uploaded test-name (TIMINGS)
        Published test-name (TIMINGS)
          test-name.test-sub-domain.workers.dev"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
    });

    it("should enable the workers.dev domain if workers_dev is true and subdomain is not already available", async () => {
      writeWranglerToml({ workers_dev: true });
      writeWorkerSource();
      mockUploadWorkerRequest({ available_on_subdomain: false });
      mockSubDomainRequest();
      mockUpdateWorkerRequest({ enabled: true });

      await runWrangler("publish ./index");

      expect(std.out).toMatchInlineSnapshot(`
        "Uploaded test-name (TIMINGS)
        Published test-name (TIMINGS)
          test-name.test-sub-domain.workers.dev"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
    });

    it("should error politely when publishing to workers_dev when there is no workers.dev subdomain", async () => {
      writeWranglerToml({
        workers_dev: true,
      });
      writeWorkerSource();
      mockUploadWorkerRequest();
      mockSubDomainRequest("does-not-exist", false);

      await expect(runWrangler("publish ./index")).rejects
        .toThrowErrorMatchingInlineSnapshot(`
              "Error: You need to register a workers.dev subdomain before publishing to workers.dev
              You can either publish your worker to one or more routes by specifying them in wrangler.toml, or register a workers.dev subdomain here:
              https://dash.cloudflare.com/some-account-id/workers/onboarding"
            `);
    });

    it("should not deploy to workers.dev if there are any routes defined", async () => {
      writeWranglerToml({
        routes: ["http://example.com/*"],
      });
      writeWorkerSource();
      mockSubDomainRequest();
      mockUploadWorkerRequest();
      mockUpdateWorkerRequest({
        enabled: false,
      });
      mockPublishRoutesRequest({ routes: ["http://example.com/*"] });
      await runWrangler("publish index.js");

      expect(std.out).toMatchInlineSnapshot(`
        "Uploaded test-name (TIMINGS)
        Published test-name (TIMINGS)
          http://example.com/*"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
      expect(std.warn).toMatchInlineSnapshot(`""`);
    });

    it("should not deploy to workers.dev if there are any routes defined (environments)", async () => {
      writeWranglerToml({
        routes: ["http://example.com/*"],
        env: {
          production: {
            routes: ["http://production.example.com/*"],
          },
        },
      });
      writeWorkerSource();
      mockSubDomainRequest();
      mockUploadWorkerRequest({ env: "production", legacyEnv: true });
      mockUpdateWorkerRequest({
        enabled: false,
        env: "production",
        legacyEnv: true,
      });
      mockPublishRoutesRequest({
        routes: ["http://production.example.com/*"],
        env: "production",
        legacyEnv: true,
      });
      await runWrangler("publish index.js --env production");

      expect(std.out).toMatchInlineSnapshot(`
        "Uploaded test-name-production (TIMINGS)
        Published test-name-production (TIMINGS)
          http://production.example.com/*"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
      expect(std.warn).toMatchInlineSnapshot(`""`);
    });

    it("should not deploy to workers.dev if there are any routes defined (only in environments)", async () => {
      writeWranglerToml({
        env: {
          production: {
            routes: ["http://production.example.com/*"],
          },
        },
      });
      writeWorkerSource();
      mockSubDomainRequest();
      mockUploadWorkerRequest({ env: "production", legacyEnv: true });
      mockUpdateWorkerRequest({
        enabled: false,
        env: "production",
        legacyEnv: true,
      });
      mockPublishRoutesRequest({
        routes: ["http://production.example.com/*"],
        env: "production",
        legacyEnv: true,
      });
      await runWrangler("publish index.js --env production");

      expect(std.out).toMatchInlineSnapshot(`
        "Uploaded test-name-production (TIMINGS)
        Published test-name-production (TIMINGS)
          http://production.example.com/*"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
      expect(std.warn).toMatchInlineSnapshot(`""`);
    });

    it("can deploy to both workers.dev and routes if both defined ", async () => {
      writeWranglerToml({
        workers_dev: true,
        routes: ["http://example.com/*"],
      });
      writeWorkerSource();
      mockSubDomainRequest();
      mockUploadWorkerRequest();
      mockUpdateWorkerRequest({
        enabled: false,
      });
      mockPublishRoutesRequest({
        routes: ["http://example.com/*"],
      });
      await runWrangler("publish index.js");

      expect(std.out).toMatchInlineSnapshot(`
        "Uploaded test-name (TIMINGS)
        Published test-name (TIMINGS)
          test-name.test-sub-domain.workers.dev
          http://example.com/*"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
      expect(std.warn).toMatchInlineSnapshot(`""`);
    });

    it("can deploy to both workers.dev and routes if both defined (environments: 1)", async () => {
      writeWranglerToml({
        workers_dev: true,
        env: {
          production: {
            routes: ["http://production.example.com/*"],
          },
        },
      });
      writeWorkerSource();
      mockSubDomainRequest();
      mockUploadWorkerRequest({ env: "production", legacyEnv: true });
      mockUpdateWorkerRequest({
        enabled: false,
        env: "production",
        legacyEnv: true,
      });
      mockPublishRoutesRequest({
        routes: ["http://production.example.com/*"],
        env: "production",
        legacyEnv: true,
      });
      await runWrangler("publish index.js --env production");

      expect(std.out).toMatchInlineSnapshot(`
        "Uploaded test-name-production (TIMINGS)
        Published test-name-production (TIMINGS)
          test-name-production.test-sub-domain.workers.dev
          http://production.example.com/*"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
      expect(std.warn).toMatchInlineSnapshot(`""`);
    });

    it("can deploy to both workers.dev and routes if both defined (environments: 2)", async () => {
      writeWranglerToml({
        env: {
          production: {
            workers_dev: true,
            routes: ["http://production.example.com/*"],
          },
        },
      });
      writeWorkerSource();
      mockSubDomainRequest();
      mockUploadWorkerRequest({ env: "production", legacyEnv: true });
      mockUpdateWorkerRequest({
        enabled: false,
        env: "production",
        legacyEnv: true,
      });
      mockPublishRoutesRequest({
        routes: ["http://production.example.com/*"],
        env: "production",
        legacyEnv: true,
      });
      await runWrangler("publish index.js --env production");

      expect(std.out).toMatchInlineSnapshot(`
        "Uploaded test-name-production (TIMINGS)
        Published test-name-production (TIMINGS)
          test-name-production.test-sub-domain.workers.dev
          http://production.example.com/*"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
      expect(std.warn).toMatchInlineSnapshot(`""`);
    });

    it("will deploy only to routes when workers_dev is false (environments 1) ", async () => {
      writeWranglerToml({
        workers_dev: false,
        env: {
          production: {
            routes: ["http://production.example.com/*"],
          },
        },
      });
      writeWorkerSource();
      mockSubDomainRequest();
      mockUploadWorkerRequest({ env: "production", legacyEnv: true });
      mockUpdateWorkerRequest({
        enabled: false,
        env: "production",
        legacyEnv: true,
      });
      mockPublishRoutesRequest({
        routes: ["http://production.example.com/*"],
        env: "production",
        legacyEnv: true,
      });
      await runWrangler("publish index.js --env production");

      expect(std.out).toMatchInlineSnapshot(`
        "Uploaded test-name-production (TIMINGS)
        Published test-name-production (TIMINGS)
          http://production.example.com/*"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
      expect(std.warn).toMatchInlineSnapshot(`""`);
    });

    it("will deploy only to routes when workers_dev is false (environments 2) ", async () => {
      writeWranglerToml({
        env: {
          production: {
            workers_dev: false,
            routes: ["http://production.example.com/*"],
          },
        },
      });
      writeWorkerSource();
      mockSubDomainRequest();
      mockUploadWorkerRequest({ env: "production", legacyEnv: true });
      mockUpdateWorkerRequest({
        enabled: false,
        env: "production",
        legacyEnv: true,
      });
      mockPublishRoutesRequest({
        routes: ["http://production.example.com/*"],
        env: "production",
        legacyEnv: true,
      });
      await runWrangler("publish index.js --env production");

      expect(std.out).toMatchInlineSnapshot(`
        "Uploaded test-name-production (TIMINGS)
        Published test-name-production (TIMINGS)
          http://production.example.com/*"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
      expect(std.warn).toMatchInlineSnapshot(`""`);
    });
  });

  describe("custom builds", () => {
    beforeEach(() => {
      // @ts-expect-error disable the mock we'd setup earlier
      // or else custom builds will timeout immediately
      global.setTimeout.mockRestore();
    });
    it("should run a custom build before publishing", async () => {
      writeWranglerToml({
        build: {
          command: `node -e "console.log('custom build'); require('fs').writeFileSync('index.js', 'export default { fetch(){ return new Response(123) } }')"`,
        },
      });

      mockUploadWorkerRequest({
        expectedEntry: "return new Response(123)",
      });
      mockSubDomainRequest();

      await runWrangler("publish index.js");
      expect(std.out).toMatchInlineSnapshot(`
        "running: node -e \\"console.log('custom build'); require('fs').writeFileSync('index.js', 'export default { fetch(){ return new Response(123) } }')\\"
        Uploaded test-name (TIMINGS)
        Published test-name (TIMINGS)
          test-name.test-sub-domain.workers.dev"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
      expect(std.warn).toMatchInlineSnapshot(`""`);
    });

    if (process.platform !== "win32") {
      it("should run a custom build of multiple steps combined by && before publishing", async () => {
        writeWranglerToml({
          build: {
            command: `echo "custom build" && echo "export default { fetch(){ return new Response(123) } }" > index.js`,
          },
        });

        mockUploadWorkerRequest({
          expectedEntry: "return new Response(123)",
        });
        mockSubDomainRequest();

        await runWrangler("publish index.js");
        expect(std.out).toMatchInlineSnapshot(`
          "running: echo \\"custom build\\" && echo \\"export default { fetch(){ return new Response(123) } }\\" > index.js
          Uploaded test-name (TIMINGS)
          Published test-name (TIMINGS)
            test-name.test-sub-domain.workers.dev"
        `);
        expect(std.err).toMatchInlineSnapshot(`""`);
        expect(std.warn).toMatchInlineSnapshot(`""`);
      });
    }

    it("should throw an error if the entry doesn't exist after the build finishes", async () => {
      writeWranglerToml({
        main: "index.js",
        build: {
          command: `node -e "console.log('custom build');"`,
        },
      });

      await expect(
        runWrangler("publish index.js")
      ).rejects.toThrowErrorMatchingInlineSnapshot(
        `"Could not resolve \\"index.js\\" after running custom build: node -e \\"console.log('custom build');\\""`
      );
      expect(std.out).toMatchInlineSnapshot(
        `"running: node -e \\"console.log('custom build');\\""`
      );
      expect(std.err).toMatchInlineSnapshot(`
        "Could not resolve \\"index.js\\" after running custom build: node -e \\"console.log('custom build');\\"

        [32m%s[0m If you think this is a bug then please create an issue at https://github.com/cloudflare/wrangler2/issues/new."
      `);
      expect(std.warn).toMatchInlineSnapshot(`""`);
    });
  });

  describe("bindings", () => {
    it("should allow bindings with different names", async () => {
      writeWranglerToml({
        durable_objects: {
          bindings: [
            {
              name: "DURABLE_OBJECT_ONE",
              class_name: "SomeDurableObject",
              script_name: "some-durable-object-worker",
            },
            {
              name: "DURABLE_OBJECT_TWO",
              class_name: "AnotherDurableObject",
              script_name: "another-durable-object-worker",
            },
          ],
        },
        kv_namespaces: [
          { binding: "KV_NAMESPACE_ONE", id: "kv-ns-one-id" },
          { binding: "KV_NAMESPACE_TWO", id: "kv-ns-two-id" },
        ],
        r2_buckets: [
          { binding: "R2_BUCKET_ONE", bucket_name: "r2-bucket-one-name" },
          { binding: "R2_BUCKET_TWO", bucket_name: "r2-bucket-two-name" },
        ],
        text_blobs: {
          TEXT_BLOB_ONE: "./my-entire-app-depends-on-this.cfg",
          TEXT_BLOB_TWO: "./the-entirety-of-human-knowledge.txt",
        },
        unsafe: {
          bindings: [
            {
              name: "UNSAFE_BINDING_ONE",
              type: "some unsafe thing",
              data: { some: { unsafe: "thing" } },
            },
            {
              name: "UNSAFE_BINDING_TWO",
              type: "another unsafe thing",
              data: 1337,
            },
          ],
        },
        vars: {
          ENV_VAR_ONE: 123,
          ENV_VAR_TWO: "Hello, I'm an environment variable",
        },
        wasm_modules: {
          WASM_MODULE_ONE: "./some_wasm.wasm",
          WASM_MODULE_TWO: "./more_wasm.wasm",
        },
      });

      writeWorkerSource({ type: "sw" });
      fs.writeFileSync("./my-entire-app-depends-on-this.cfg", "config = value");
      fs.writeFileSync(
        "./the-entirety-of-human-knowledge.txt",
        "Everything's bigger in Texas"
      );
      fs.writeFileSync("./some_wasm.wasm", "some wasm");
      fs.writeFileSync("./more_wasm.wasm", "more wasm");

      mockUploadWorkerRequest({
        expectedType: "sw",
        expectedBindings: [
          {
            name: "KV_NAMESPACE_ONE",
            namespace_id: "kv-ns-one-id",
            type: "kv_namespace",
          },
          {
            name: "KV_NAMESPACE_TWO",
            namespace_id: "kv-ns-two-id",
            type: "kv_namespace",
          },
          {
            class_name: "SomeDurableObject",
            name: "DURABLE_OBJECT_ONE",
            script_name: "some-durable-object-worker",
            type: "durable_object_namespace",
          },
          {
            class_name: "AnotherDurableObject",
            name: "DURABLE_OBJECT_TWO",
            script_name: "another-durable-object-worker",
            type: "durable_object_namespace",
          },
          {
            bucket_name: "r2-bucket-one-name",
            name: "R2_BUCKET_ONE",
            type: "r2_bucket",
          },
          {
            bucket_name: "r2-bucket-two-name",
            name: "R2_BUCKET_TWO",
            type: "r2_bucket",
          },
          { json: 123, name: "ENV_VAR_ONE", type: "json" },
          {
            name: "ENV_VAR_TWO",
            text: "Hello, I'm an environment variable",
            type: "plain_text",
          },
          {
            name: "WASM_MODULE_ONE",
            part: "WASM_MODULE_ONE",
            type: "wasm_module",
          },
          {
            name: "WASM_MODULE_TWO",
            part: "WASM_MODULE_TWO",
            type: "wasm_module",
          },
          { name: "TEXT_BLOB_ONE", part: "TEXT_BLOB_ONE", type: "text_blob" },
          { name: "TEXT_BLOB_TWO", part: "TEXT_BLOB_TWO", type: "text_blob" },
          {
            data: { some: { unsafe: "thing" } },
            name: "UNSAFE_BINDING_ONE",
            type: "some unsafe thing",
          },
          {
            data: 1337,
            name: "UNSAFE_BINDING_TWO",
            type: "another unsafe thing",
          },
        ],
      });
      mockSubDomainRequest();

      await expect(runWrangler("publish index.js")).resolves.toBeUndefined();
      expect(std.out).toMatchInlineSnapshot(`
        "Uploaded test-name (TIMINGS)
        Published test-name (TIMINGS)
          test-name.test-sub-domain.workers.dev"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
      expect(std.warn).toMatchInlineSnapshot(`
        "Processing wrangler.toml configuration:
          - \\"unsafe\\" fields are experimental and may change or break at any time."
      `);
    });

    it("should error when bindings of different types have the same name", async () => {
      writeWranglerToml({
        durable_objects: {
          bindings: [
            {
              name: "CONFLICTING_NAME_ONE",
              class_name: "SomeDurableObject",
              script_name: "some-durable-object-worker",
            },
            {
              name: "CONFLICTING_NAME_TWO",
              class_name: "AnotherDurableObject",
              script_name: "another-durable-object-worker",
            },
          ],
        },
        kv_namespaces: [
          { binding: "CONFLICTING_NAME_ONE", id: "kv-ns-one-id" },
          { binding: "CONFLICTING_NAME_TWO", id: "kv-ns-two-id" },
        ],
        r2_buckets: [
          {
            binding: "CONFLICTING_NAME_ONE",
            bucket_name: "r2-bucket-one-name",
          },
          {
            binding: "CONFLICTING_NAME_THREE",
            bucket_name: "r2-bucket-two-name",
          },
        ],
        text_blobs: {
          CONFLICTING_NAME_THREE: "./my-entire-app-depends-on-this.cfg",
          CONFLICTING_NAME_FOUR: "./the-entirety-of-human-knowledge.txt",
        },
        unsafe: {
          bindings: [
            {
              name: "CONFLICTING_NAME_THREE",
              type: "some unsafe thing",
              data: { some: { unsafe: "thing" } },
            },
            {
              name: "CONFLICTING_NAME_FOUR",
              type: "another unsafe thing",
              data: 1337,
            },
          ],
        },
        vars: {
          ENV_VAR_ONE: 123,
          CONFLICTING_NAME_THREE: "Hello, I'm an environment variable",
        },
        wasm_modules: {
          WASM_MODULE_ONE: "./some_wasm.wasm",
          CONFLICTING_NAME_THREE: "./more_wasm.wasm",
        },
      });

      writeWorkerSource({ type: "sw" });
      fs.writeFileSync("./my-entire-app-depends-on-this.cfg", "config = value");
      fs.writeFileSync(
        "./the-entirety-of-human-knowledge.txt",
        "Everything's bigger in Texas"
      );
      fs.writeFileSync("./some_wasm.wasm", "some wasm");
      fs.writeFileSync("./more_wasm.wasm", "more wasm");

      await expect(runWrangler("publish index.js")).rejects
        .toMatchInlineSnapshot(`
              [Error: Processing wrangler.toml configuration:
                - CONFLICTING_NAME_ONE assigned to Durable Object, KV Namespace, and R2 Bucket bindings.
                - CONFLICTING_NAME_TWO assigned to Durable Object and KV Namespace bindings.
                - CONFLICTING_NAME_THREE assigned to R2 Bucket, Text Blob, Unsafe, Environment Variable, and WASM Module bindings.
                - CONFLICTING_NAME_FOUR assigned to Text Blob and Unsafe bindings.
                - Bindings must have unique names, so that they can all be referenced in the worker.
                  Please change your bindings to have unique names.]
            `);
      expect(std.out).toMatchInlineSnapshot(`""`);
      expect(std.err).toMatchInlineSnapshot(`
        "Processing wrangler.toml configuration:
          - CONFLICTING_NAME_ONE assigned to Durable Object, KV Namespace, and R2 Bucket bindings.
          - CONFLICTING_NAME_TWO assigned to Durable Object and KV Namespace bindings.
          - CONFLICTING_NAME_THREE assigned to R2 Bucket, Text Blob, Unsafe, Environment Variable, and WASM Module bindings.
          - CONFLICTING_NAME_FOUR assigned to Text Blob and Unsafe bindings.
          - Bindings must have unique names, so that they can all be referenced in the worker.
            Please change your bindings to have unique names.

        [32m%s[0m If you think this is a bug then please create an issue at https://github.com/cloudflare/wrangler2/issues/new."
      `);
      expect(std.warn).toMatchInlineSnapshot(`
        "Processing wrangler.toml configuration:
          - \\"unsafe\\" fields are experimental and may change or break at any time."
      `);
    });

    it("should error when bindings of the same type have the same name", async () => {
      writeWranglerToml({
        durable_objects: {
          bindings: [
            {
              name: "CONFLICTING_DURABLE_OBJECT_NAME",
              class_name: "SomeDurableObject",
              script_name: "some-durable-object-worker",
            },
            {
              name: "CONFLICTING_DURABLE_OBJECT_NAME",
              class_name: "AnotherDurableObject",
              script_name: "another-durable-object-worker",
            },
          ],
        },
        kv_namespaces: [
          { binding: "CONFLICTING_KV_NAMESPACE_NAME", id: "kv-ns-one-id" },
          { binding: "CONFLICTING_KV_NAMESPACE_NAME", id: "kv-ns-two-id" },
        ],
        r2_buckets: [
          {
            binding: "CONFLICTING_R2_BUCKET_NAME",
            bucket_name: "r2-bucket-one-name",
          },
          {
            binding: "CONFLICTING_R2_BUCKET_NAME",
            bucket_name: "r2-bucket-two-name",
          },
        ],
        unsafe: {
          bindings: [
            {
              name: "CONFLICTING_UNSAFE_NAME",
              type: "some unsafe thing",
              data: { some: { unsafe: "thing" } },
            },
            {
              name: "CONFLICTING_UNSAFE_NAME",
              type: "another unsafe thing",
              data: 1337,
            },
          ],
        },
        // text_blobs, vars, and wasm_modules are fine because they're object literals,
        // and by definition cannot have two keys of the same name
        //
        // text_blobs: {
        //   CONFLICTING_TEXT_BLOB_NAME: "./my-entire-app-depends-on-this.cfg",
        //   CONFLICTING_TEXT_BLOB_NAME: "./the-entirety-of-human-knowledge.txt",
        // },
        // vars: {
        //   CONFLICTING_VARS_NAME: 123,
        //   CONFLICTING_VARS_NAME: "Hello, I'm an environment variable",
        // },
        // wasm_modules: {
        //   CONFLICTING_WASM_MODULE_NAME: "./some_wasm.wasm",
        //   CONFLICTING_WASM_MODULE_NAME: "./more_wasm.wasm",
        // },
      });

      writeWorkerSource({ type: "sw" });

      await expect(runWrangler("publish index.js")).rejects
        .toMatchInlineSnapshot(`
              [Error: Processing wrangler.toml configuration:
                - CONFLICTING_DURABLE_OBJECT_NAME assigned to multiple Durable Object bindings.
                - CONFLICTING_KV_NAMESPACE_NAME assigned to multiple KV Namespace bindings.
                - CONFLICTING_R2_BUCKET_NAME assigned to multiple R2 Bucket bindings.
                - CONFLICTING_UNSAFE_NAME assigned to multiple Unsafe bindings.
                - Bindings must have unique names, so that they can all be referenced in the worker.
                  Please change your bindings to have unique names.]
            `);
      expect(std.out).toMatchInlineSnapshot(`""`);
      expect(std.err).toMatchInlineSnapshot(`
        "Processing wrangler.toml configuration:
          - CONFLICTING_DURABLE_OBJECT_NAME assigned to multiple Durable Object bindings.
          - CONFLICTING_KV_NAMESPACE_NAME assigned to multiple KV Namespace bindings.
          - CONFLICTING_R2_BUCKET_NAME assigned to multiple R2 Bucket bindings.
          - CONFLICTING_UNSAFE_NAME assigned to multiple Unsafe bindings.
          - Bindings must have unique names, so that they can all be referenced in the worker.
            Please change your bindings to have unique names.

        [32m%s[0m If you think this is a bug then please create an issue at https://github.com/cloudflare/wrangler2/issues/new."
      `);
      expect(std.warn).toMatchInlineSnapshot(`
        "Processing wrangler.toml configuration:
          - \\"unsafe\\" fields are experimental and may change or break at any time."
      `);
    });

    it("should error correctly when bindings of the same and different types use the same name", async () => {
      writeWranglerToml({
        durable_objects: {
          bindings: [
            {
              name: "CONFLICTING_DURABLE_OBJECT_NAME",
              class_name: "SomeDurableObject",
              script_name: "some-durable-object-worker",
            },
            {
              name: "CONFLICTING_DURABLE_OBJECT_NAME",
              class_name: "AnotherDurableObject",
              script_name: "another-durable-object-worker",
            },
          ],
        },
        kv_namespaces: [
          {
            binding: "CONFLICTING_KV_NAMESPACE_NAME",
            id: "kv-ns-one-id",
          },
          {
            binding: "CONFLICTING_KV_NAMESPACE_NAME",
            id: "kv-ns-two-id",
          },
          { binding: "CONFLICTING_NAME_ONE", id: "kv-ns-three-id" },
          { binding: "CONFLICTING_NAME_TWO", id: "kv-ns-four-id" },
        ],
        r2_buckets: [
          {
            binding: "CONFLICTING_R2_BUCKET_NAME",
            bucket_name: "r2-bucket-one-name",
          },
          {
            binding: "CONFLICTING_R2_BUCKET_NAME",
            bucket_name: "r2-bucket-two-name",
          },
          {
            binding: "CONFLICTING_NAME_THREE",
            bucket_name: "r2-bucket-three-name",
          },
          {
            binding: "CONFLICTING_NAME_FOUR",
            bucket_name: "r2-bucket-four-name",
          },
        ],
        text_blobs: {
          CONFLICTING_NAME_THREE: "./my-entire-app-depends-on-this.cfg",
          CONFLICTING_NAME_FOUR: "./the-entirety-of-human-knowledge.txt",
        },
        unsafe: {
          bindings: [
            {
              name: "CONFLICTING_UNSAFE_NAME",
              type: "some unsafe thing",
              data: { some: { unsafe: "thing" } },
            },
            {
              name: "CONFLICTING_UNSAFE_NAME",
              type: "another unsafe thing",
              data: 1337,
            },
            {
              name: "CONFLICTING_NAME_THREE",
              type: "yet another unsafe thing",
              data: "how is a string unsafe?",
            },
            {
              name: "CONFLICTING_NAME_FOUR",
              type: "a fourth unsafe thing",
              data: null,
            },
          ],
        },
        vars: {
          ENV_VAR_ONE: 123,
          CONFLICTING_NAME_THREE: "Hello, I'm an environment variable",
        },
        wasm_modules: {
          WASM_MODULE_ONE: "./some_wasm.wasm",
          CONFLICTING_NAME_THREE: "./more_wasm.wasm",
        },
      });

      writeWorkerSource({ type: "sw" });
      fs.writeFileSync("./my-entire-app-depends-on-this.cfg", "config = value");
      fs.writeFileSync(
        "./the-entirety-of-human-knowledge.txt",
        "Everything's bigger in Texas"
      );
      fs.writeFileSync("./some_wasm.wasm", "some wasm");
      fs.writeFileSync("./more_wasm.wasm", "more wasm");

      await expect(runWrangler("publish index.js")).rejects
        .toMatchInlineSnapshot(`
              [Error: Processing wrangler.toml configuration:
                - CONFLICTING_DURABLE_OBJECT_NAME assigned to multiple Durable Object bindings.
                - CONFLICTING_KV_NAMESPACE_NAME assigned to multiple KV Namespace bindings.
                - CONFLICTING_R2_BUCKET_NAME assigned to multiple R2 Bucket bindings.
                - CONFLICTING_NAME_THREE assigned to R2 Bucket, Text Blob, Unsafe, Environment Variable, and WASM Module bindings.
                - CONFLICTING_NAME_FOUR assigned to R2 Bucket, Text Blob, and Unsafe bindings.
                - CONFLICTING_UNSAFE_NAME assigned to multiple Unsafe bindings.
                - Bindings must have unique names, so that they can all be referenced in the worker.
                  Please change your bindings to have unique names.]
            `);
      expect(std.out).toMatchInlineSnapshot(`""`);
      expect(std.err).toMatchInlineSnapshot(`
        "Processing wrangler.toml configuration:
          - CONFLICTING_DURABLE_OBJECT_NAME assigned to multiple Durable Object bindings.
          - CONFLICTING_KV_NAMESPACE_NAME assigned to multiple KV Namespace bindings.
          - CONFLICTING_R2_BUCKET_NAME assigned to multiple R2 Bucket bindings.
          - CONFLICTING_NAME_THREE assigned to R2 Bucket, Text Blob, Unsafe, Environment Variable, and WASM Module bindings.
          - CONFLICTING_NAME_FOUR assigned to R2 Bucket, Text Blob, and Unsafe bindings.
          - CONFLICTING_UNSAFE_NAME assigned to multiple Unsafe bindings.
          - Bindings must have unique names, so that they can all be referenced in the worker.
            Please change your bindings to have unique names.

        [32m%s[0m If you think this is a bug then please create an issue at https://github.com/cloudflare/wrangler2/issues/new."
      `);
      expect(std.warn).toMatchInlineSnapshot(`
        "Processing wrangler.toml configuration:
          - \\"unsafe\\" fields are experimental and may change or break at any time."
      `);
    });

    describe("[wasm_modules]", () => {
      it("should be able to define wasm modules for service-worker format workers", async () => {
        writeWranglerToml({
          wasm_modules: {
            TESTWASMNAME: "./path/to/test.wasm",
          },
        });
        writeWorkerSource({ type: "sw" });
        fs.mkdirSync("./path/to", { recursive: true });
        fs.writeFileSync("./path/to/test.wasm", "SOME WASM CONTENT");
        mockUploadWorkerRequest({
          expectedType: "sw",
          expectedModules: { TESTWASMNAME: "SOME WASM CONTENT" },
          expectedBindings: [
            { name: "TESTWASMNAME", part: "TESTWASMNAME", type: "wasm_module" },
          ],
        });
        mockSubDomainRequest();
        await runWrangler("publish index.js");
        expect(std.out).toMatchInlineSnapshot(`
                  "Uploaded test-name (TIMINGS)
                  Published test-name (TIMINGS)
                    test-name.test-sub-domain.workers.dev"
              `);
        expect(std.err).toMatchInlineSnapshot(`""`);
        expect(std.warn).toMatchInlineSnapshot(`""`);
      });

      it("should error when defining wasm modules for modules format workers", async () => {
        writeWranglerToml({
          wasm_modules: {
            TESTWASMNAME: "./path/to/test.wasm",
          },
        });
        writeWorkerSource({ type: "esm" });
        fs.mkdirSync("./path/to", { recursive: true });
        fs.writeFileSync("./path/to/test.wasm", "SOME WASM CONTENT");

        await expect(
          runWrangler("publish index.js")
        ).rejects.toThrowErrorMatchingInlineSnapshot(
          `"You cannot configure [wasm_modules] with an ES module worker. Instead, import the .wasm module directly in your code"`
        );
        expect(std.out).toMatchInlineSnapshot(`""`);
        expect(std.err).toMatchInlineSnapshot(`
                  "You cannot configure [wasm_modules] with an ES module worker. Instead, import the .wasm module directly in your code

                  [32m%s[0m If you think this is a bug then please create an issue at https://github.com/cloudflare/wrangler2/issues/new."
              `);
        expect(std.warn).toMatchInlineSnapshot(`""`);
      });

      it("should resolve wasm modules relative to the wrangler.toml file", async () => {
        fs.mkdirSync("./path/to/and/the/path/to/", { recursive: true });
        fs.writeFileSync(
          "./path/to/wrangler.toml",
          TOML.stringify({
            compatibility_date: "2022-01-12",
            name: "test-name",
            wasm_modules: {
              TESTWASMNAME: "./and/the/path/to/test.wasm",
            },
          }),

          "utf-8"
        );

        writeWorkerSource({ type: "sw" });
        fs.writeFileSync(
          "./path/to/and/the/path/to/test.wasm",
          "SOME WASM CONTENT"
        );
        mockUploadWorkerRequest({
          expectedType: "sw",
          expectedModules: { TESTWASMNAME: "SOME WASM CONTENT" },
          expectedBindings: [
            { name: "TESTWASMNAME", part: "TESTWASMNAME", type: "wasm_module" },
          ],
          expectedCompatibilityDate: "2022-01-12",
        });
        mockSubDomainRequest();
        await runWrangler("publish index.js --config ./path/to/wrangler.toml");
        expect(std.out).toMatchInlineSnapshot(`
                  "Uploaded test-name (TIMINGS)
                  Published test-name (TIMINGS)
                    test-name.test-sub-domain.workers.dev"
              `);
        expect(std.err).toMatchInlineSnapshot(`""`);
        expect(std.warn).toMatchInlineSnapshot(`""`);
      });

      it("should be able to import .wasm modules from service-worker format workers", async () => {
        writeWranglerToml();
        fs.writeFileSync(
          "./index.js",
          "import TESTWASMNAME from './test.wasm';"
        );
        fs.writeFileSync("./test.wasm", "SOME WASM CONTENT");
        mockUploadWorkerRequest({
          expectedType: "sw",
          expectedModules: {
            __94b240d0d692281e6467aa42043986e5c7eea034_test_wasm:
              "SOME WASM CONTENT",
          },
          expectedBindings: [
            {
              name: "__94b240d0d692281e6467aa42043986e5c7eea034_test_wasm",
              part: "__94b240d0d692281e6467aa42043986e5c7eea034_test_wasm",
              type: "wasm_module",
            },
          ],
        });
        mockSubDomainRequest();
        await runWrangler("publish index.js");
        expect(std.out).toMatchInlineSnapshot(`
                  "Uploaded test-name (TIMINGS)
                  Published test-name (TIMINGS)
                    test-name.test-sub-domain.workers.dev"
              `);
        expect(std.err).toMatchInlineSnapshot(`""`);
        expect(std.warn).toMatchInlineSnapshot(`""`);
      });
    });

    describe("[text_blobs]", () => {
      it("should be able to define text blobs for service-worker format workers", async () => {
        writeWranglerToml({
          text_blobs: {
            TESTTEXTBLOBNAME: "./path/to/text.file",
          },
        });
        writeWorkerSource({ type: "sw" });
        fs.mkdirSync("./path/to", { recursive: true });
        fs.writeFileSync("./path/to/text.file", "SOME TEXT CONTENT");
        mockUploadWorkerRequest({
          expectedType: "sw",
          expectedModules: { TESTTEXTBLOBNAME: "SOME TEXT CONTENT" },
          expectedBindings: [
            {
              name: "TESTTEXTBLOBNAME",
              part: "TESTTEXTBLOBNAME",
              type: "text_blob",
            },
          ],
        });
        mockSubDomainRequest();
        await runWrangler("publish index.js");
        expect(std.out).toMatchInlineSnapshot(`
                  "Uploaded test-name (TIMINGS)
                  Published test-name (TIMINGS)
                    test-name.test-sub-domain.workers.dev"
              `);
        expect(std.err).toMatchInlineSnapshot(`""`);
        expect(std.warn).toMatchInlineSnapshot(`""`);
      });

      it("should error when defining text blobs for modules format workers", async () => {
        writeWranglerToml({
          text_blobs: {
            TESTTEXTBLOBNAME: "./path/to/text.file",
          },
        });
        writeWorkerSource({ type: "esm" });
        fs.mkdirSync("./path/to", { recursive: true });
        fs.writeFileSync("./path/to/text.file", "SOME TEXT CONTENT");

        await expect(
          runWrangler("publish index.js")
        ).rejects.toThrowErrorMatchingInlineSnapshot(
          `"You cannot configure [text_blobs] with an ES module worker. Instead, import the file directly in your code, and optionally configure \`[build.upload.rules]\` in your wrangler.toml"`
        );
        expect(std.out).toMatchInlineSnapshot(`""`);
        expect(std.err).toMatchInlineSnapshot(`
                  "You cannot configure [text_blobs] with an ES module worker. Instead, import the file directly in your code, and optionally configure \`[build.upload.rules]\` in your wrangler.toml

                  [32m%s[0m If you think this is a bug then please create an issue at https://github.com/cloudflare/wrangler2/issues/new."
              `);
        expect(std.warn).toMatchInlineSnapshot(`""`);
      });

      it("should resolve text blobs relative to the wrangler.toml file", async () => {
        fs.mkdirSync("./path/to/and/the/path/to/", { recursive: true });
        fs.writeFileSync(
          "./path/to/wrangler.toml",
          TOML.stringify({
            compatibility_date: "2022-01-12",
            name: "test-name",
            text_blobs: {
              TESTTEXTBLOBNAME: "./and/the/path/to/text.file",
            },
          }),

          "utf-8"
        );

        writeWorkerSource({ type: "sw" });
        fs.writeFileSync(
          "./path/to/and/the/path/to/text.file",
          "SOME TEXT CONTENT"
        );
        mockUploadWorkerRequest({
          expectedType: "sw",
          expectedModules: { TESTTEXTBLOBNAME: "SOME TEXT CONTENT" },
          expectedBindings: [
            {
              name: "TESTTEXTBLOBNAME",
              part: "TESTTEXTBLOBNAME",
              type: "text_blob",
            },
          ],
          expectedCompatibilityDate: "2022-01-12",
        });
        mockSubDomainRequest();
        await runWrangler("publish index.js --config ./path/to/wrangler.toml");
        expect(std.out).toMatchInlineSnapshot(`
                  "Uploaded test-name (TIMINGS)
                  Published test-name (TIMINGS)
                    test-name.test-sub-domain.workers.dev"
              `);
        expect(std.err).toMatchInlineSnapshot(`""`);
        expect(std.warn).toMatchInlineSnapshot(`""`);
      });
    });

    describe("[vars]", () => {
      it("should support json bindings", async () => {
        writeWranglerToml({
          vars: {
            text: "plain ol' string",
            count: 1,
            complex: { enabled: true, id: 123 },
          },
        });
        writeWorkerSource();
        mockSubDomainRequest();
        mockUploadWorkerRequest({
          expectedBindings: [
            { name: "text", type: "plain_text", text: "plain ol' string" },
            { name: "count", type: "json", json: 1 },
            {
              name: "complex",
              type: "json",
              json: { enabled: true, id: 123 },
            },
          ],
        });

        await runWrangler("publish index.js");
        expect(std.out).toMatchInlineSnapshot(`
                  "Uploaded test-name (TIMINGS)
                  Published test-name (TIMINGS)
                    test-name.test-sub-domain.workers.dev"
              `);
        expect(std.err).toMatchInlineSnapshot(`""`);
        expect(std.warn).toMatchInlineSnapshot(`""`);
      });
    });

    describe("[r2_buckets]", () => {
      it("should support r2 bucket bindings", async () => {
        writeWranglerToml({
          r2_buckets: [{ binding: "FOO", bucket_name: "foo-bucket" }],
        });
        writeWorkerSource();
        mockSubDomainRequest();
        mockUploadWorkerRequest({
          expectedBindings: [
            { bucket_name: "foo-bucket", name: "FOO", type: "r2_bucket" },
          ],
        });

        await runWrangler("publish index.js");
        expect(std.out).toMatchInlineSnapshot(`
                  "Uploaded test-name (TIMINGS)
                  Published test-name (TIMINGS)
                    test-name.test-sub-domain.workers.dev"
              `);
        expect(std.err).toMatchInlineSnapshot(`""`);
        expect(std.warn).toMatchInlineSnapshot(`""`);
      });
    });

    describe("[durable_objects]", () => {
      it("should support durable object bindings", async () => {
        writeWranglerToml({
          durable_objects: {
            bindings: [
              {
                name: "EXAMPLE_DO_BINDING",
                class_name: "ExampleDurableObject",
              },
            ],
          },
        });
        writeWorkerSource({ type: "esm" });
        mockSubDomainRequest();
        mockUploadWorkerRequest({
          expectedBindings: [
            {
              class_name: "ExampleDurableObject",
              name: "EXAMPLE_DO_BINDING",
              type: "durable_object_namespace",
            },
          ],
        });

        await runWrangler("publish index.js");
        expect(std.out).toMatchInlineSnapshot(`
                  "Uploaded test-name (TIMINGS)
                  Published test-name (TIMINGS)
                    test-name.test-sub-domain.workers.dev"
              `);
        expect(std.err).toMatchInlineSnapshot(`""`);
        expect(std.warn).toMatchInlineSnapshot(`""`);
      });

      it("should support service-workers binding to external durable objects", async () => {
        writeWranglerToml({
          durable_objects: {
            bindings: [
              {
                name: "EXAMPLE_DO_BINDING",
                class_name: "ExampleDurableObject",
                script_name: "example-do-binding-worker",
              },
            ],
          },
        });
        writeWorkerSource({ type: "sw" });
        mockSubDomainRequest();
        mockUploadWorkerRequest({
          expectedType: "sw",
          expectedBindings: [
            {
              name: "EXAMPLE_DO_BINDING",
              class_name: "ExampleDurableObject",
              script_name: "example-do-binding-worker",
              type: "durable_object_namespace",
            },
          ],
        });

        await runWrangler("publish index.js");
        expect(std.out).toMatchInlineSnapshot(`
                  "Uploaded test-name (TIMINGS)
                  Published test-name (TIMINGS)
                    test-name.test-sub-domain.workers.dev"
              `);
        expect(std.err).toMatchInlineSnapshot(`""`);
        expect(std.warn).toMatchInlineSnapshot(`""`);
      });

      it("should support module workers implementing durable objects", async () => {
        writeWranglerToml({
          durable_objects: {
            bindings: [
              {
                name: "EXAMPLE_DO_BINDING",
                class_name: "ExampleDurableObject",
              },
            ],
          },
        });
        writeWorkerSource({ type: "esm" });
        mockSubDomainRequest();
        mockUploadWorkerRequest({
          expectedType: "esm",
          expectedBindings: [
            {
              name: "EXAMPLE_DO_BINDING",
              class_name: "ExampleDurableObject",
              type: "durable_object_namespace",
            },
          ],
        });

        await runWrangler("publish index.js");
        expect(std.out).toMatchInlineSnapshot(`
                  "Uploaded test-name (TIMINGS)
                  Published test-name (TIMINGS)
                    test-name.test-sub-domain.workers.dev"
              `);
        expect(std.err).toMatchInlineSnapshot(`""`);
        expect(std.warn).toMatchInlineSnapshot(`""`);
      });

      it("should error when detecting service workers implementing  durable objects", async () => {
        writeWranglerToml({
          durable_objects: {
            bindings: [
              {
                name: "EXAMPLE_DO_BINDING",
                class_name: "ExampleDurableObject",
              },
            ],
          },
        });
        writeWorkerSource({ type: "sw" });
        mockSubDomainRequest();

        await expect(runWrangler("publish index.js")).rejects
          .toThrowErrorMatchingInlineSnapshot(`
                              "You seem to be trying to use Durable Objects in a Worker written with Service Worker syntax.
                              You can use Durable Objects defined in other Workers by specifying a \`script_name\` in your wrangler.toml, where \`script_name\` is the name of the Worker that implements that Durable Object. For example:
                              { name = EXAMPLE_DO_BINDING, class_name = ExampleDurableObject } ==> { name = EXAMPLE_DO_BINDING, class_name = ExampleDurableObject, script_name = example-do-binding-worker }
                              Alternatively, migrate your worker to ES Module syntax to implement a Durable Object in this Worker:
                              https://developers.cloudflare.com/workers/learning/migrating-to-module-workers/"
                          `);
      });
    });

    describe("[unsafe]", () => {
      it("should warn if using unsafe bindings", async () => {
        writeWranglerToml({
          unsafe: {
            bindings: [
              {
                name: "my-binding",
                type: "binding-type",
                param: "binding-param",
              },
            ],
          },
        });
        writeWorkerSource();
        mockSubDomainRequest();
        mockUploadWorkerRequest({
          expectedBindings: [
            {
              name: "my-binding",
              type: "binding-type",
              param: "binding-param",
            },
          ],
        });

        await runWrangler("publish index.js");
        expect(std.out).toMatchInlineSnapshot(`
                  "Uploaded test-name (TIMINGS)
                  Published test-name (TIMINGS)
                    test-name.test-sub-domain.workers.dev"
              `);
        expect(std.err).toMatchInlineSnapshot(`""`);
        expect(std.warn).toMatchInlineSnapshot(`
                  "Processing wrangler.toml configuration:
                    - \\"unsafe\\" fields are experimental and may change or break at any time."
              `);
      });
      it("should warn if using unsafe bindings already handled by wrangler", async () => {
        writeWranglerToml({
          unsafe: {
            bindings: [
              {
                name: "my-binding",
                type: "plain_text",
                text: "text",
              },
            ],
          },
        });
        writeWorkerSource();
        mockSubDomainRequest();
        mockUploadWorkerRequest({
          expectedBindings: [
            {
              name: "my-binding",
              type: "plain_text",
              text: "text",
            },
          ],
        });

        await runWrangler("publish index.js");
        expect(std.out).toMatchInlineSnapshot(`
                  "Uploaded test-name (TIMINGS)
                  Published test-name (TIMINGS)
                    test-name.test-sub-domain.workers.dev"
              `);
        expect(std.err).toMatchInlineSnapshot(`""`);
        expect(std.warn).toMatchInlineSnapshot(`
                  "Processing wrangler.toml configuration:
                    - \\"unsafe\\" fields are experimental and may change or break at any time.
                    - \\"unsafe.bindings[0]\\": {\\"name\\":\\"my-binding\\",\\"type\\":\\"plain_text\\",\\"text\\":\\"text\\"}
                      - The binding type \\"plain_text\\" is directly supported by wrangler.
                        Consider migrating this unsafe binding to a format for 'plain_text' bindings that is supported by wrangler for optimal support.
                        For more details, see https://developers.cloudflare.com/workers/cli-wrangler/configuration"
              `);
      });
    });
  });

  describe("upload rules", () => {
    it("should be able to define rules for uploading non-js modules (sw)", async () => {
      writeWranglerToml({
        rules: [{ type: "Text", globs: ["**/*.file"], fallthrough: true }],
      });
      fs.writeFileSync("./index.js", `import TEXT from './text.file';`);
      fs.writeFileSync("./text.file", "SOME TEXT CONTENT");
      mockSubDomainRequest();
      mockUploadWorkerRequest({
        expectedType: "sw",
        expectedBindings: [
          {
            name: "__2d91d1c4dd6e57d4f5432187ab7c25f45a8973f0_text_file",
            part: "__2d91d1c4dd6e57d4f5432187ab7c25f45a8973f0_text_file",
            type: "text_blob",
          },
        ],
        expectedModules: {
          __2d91d1c4dd6e57d4f5432187ab7c25f45a8973f0_text_file:
            "SOME TEXT CONTENT",
        },
      });
      await runWrangler("publish index.js");
      expect(std.out).toMatchInlineSnapshot(`
        "Uploaded test-name (TIMINGS)
        Published test-name (TIMINGS)
          test-name.test-sub-domain.workers.dev"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
      expect(std.warn).toMatchInlineSnapshot(`""`);
    });

    it("should be able to define rules for uploading non-js modules (esm)", async () => {
      writeWranglerToml({
        rules: [{ type: "Text", globs: ["**/*.file"], fallthrough: true }],
      });
      fs.writeFileSync(
        "./index.js",
        `import TEXT from './text.file'; export default {};`
      );
      fs.writeFileSync("./text.file", "SOME TEXT CONTENT");
      mockSubDomainRequest();
      mockUploadWorkerRequest({
        expectedType: "esm",
        expectedBindings: [],
        expectedModules: {
          "./2d91d1c4dd6e57d4f5432187ab7c25f45a8973f0-text.file":
            "SOME TEXT CONTENT",
        },
      });
      await runWrangler("publish index.js");
      expect(std.out).toMatchInlineSnapshot(`
        "Uploaded test-name (TIMINGS)
        Published test-name (TIMINGS)
          test-name.test-sub-domain.workers.dev"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
      expect(std.warn).toMatchInlineSnapshot(`""`);
    });

    it("should log a deprecation warning when using `build.upload.rules`", async () => {
      writeWranglerToml({
        build: {
          upload: {
            rules: [{ type: "Text", globs: ["**/*.file"], fallthrough: true }],
          },
        },
      });
      fs.writeFileSync(
        "./index.js",
        `import TEXT from './text.file'; export default {};`
      );
      fs.writeFileSync("./text.file", "SOME TEXT CONTENT");
      mockSubDomainRequest();
      mockUploadWorkerRequest({
        expectedType: "esm",
        expectedBindings: [],
        expectedModules: {
          "./2d91d1c4dd6e57d4f5432187ab7c25f45a8973f0-text.file":
            "SOME TEXT CONTENT",
        },
      });
      await runWrangler("publish index.js");
      expect(std.out).toMatchInlineSnapshot(`
        "Uploaded test-name (TIMINGS)
        Published test-name (TIMINGS)
          test-name.test-sub-domain.workers.dev"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
      expect(std.warn).toMatchInlineSnapshot(`
        "Processing wrangler.toml configuration:
          - DEPRECATION: The \`build.upload.rules\` config field is no longer used, the rules should be specified via the \`rules\` config field. Delete the \`build.upload\` field from the configuration file, and add this:
            \`\`\`
            [[rules]]
            type = \\"Text\\"
            globs = [ \\"**/*.file\\" ]
            fallthrough = true
            \`\`\`"
      `);
    });

    it("should be able to use fallthrough:true for multiple rules", async () => {
      writeWranglerToml({
        rules: [
          { type: "Text", globs: ["**/*.file"], fallthrough: true },
          { type: "Text", globs: ["**/*.other"], fallthrough: true },
        ],
      });
      fs.writeFileSync(
        "./index.js",
        `import TEXT from './text.file'; import OTHER from './other.other'; export default {};`
      );
      fs.writeFileSync("./text.file", "SOME TEXT CONTENT");
      fs.writeFileSync("./other.other", "SOME OTHER TEXT CONTENT");
      mockSubDomainRequest();
      mockUploadWorkerRequest({
        expectedType: "esm",
        expectedBindings: [],
        expectedModules: {
          "./2d91d1c4dd6e57d4f5432187ab7c25f45a8973f0-text.file":
            "SOME TEXT CONTENT",
          "./16347a01366873ed80fe45115119de3c92ab8db0-other.other":
            "SOME OTHER TEXT CONTENT",
        },
      });
      await runWrangler("publish index.js");
      expect(std.out).toMatchInlineSnapshot(`
        "Uploaded test-name (TIMINGS)
        Published test-name (TIMINGS)
          test-name.test-sub-domain.workers.dev"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
      expect(std.warn).toMatchInlineSnapshot(`""`);
    });

    it("should be able to use fallthrough:false for multiple rules", async () => {
      writeWranglerToml({
        rules: [
          { type: "Text", globs: ["**/*.file"], fallthrough: false },
          { type: "Text", globs: ["**/*.other"] },
        ],
      });
      fs.writeFileSync(
        "./index.js",
        `import TEXT from './text.file'; import OTHER from './other.other'; export default {};`
      );
      fs.writeFileSync("./text.file", "SOME TEXT CONTENT");
      fs.writeFileSync("./other.other", "SOME OTHER TEXT CONTENT");

      // We throw an error when we come across a file that matched a rule
      // but was skipped because of fallthrough = false
      let err: Error | undefined;
      try {
        await runWrangler("publish index.js");
      } catch (e) {
        err = e as Error;
      }
      expect(err?.message).toMatch(
        `The file ./other.other matched a module rule in your configuration ({"type":"Text","globs":["**/*.other"]}), but was ignored because a previous rule with the same type was not marked as \`fallthrough = true\`.`
      );
    });

    it("should warn when multiple rules for the same type do not have fallback defined", async () => {
      writeWranglerToml({
        rules: [
          { type: "Text", globs: ["**/*.file"] },
          { type: "Text", globs: ["**/*.other"] },
        ],
      });
      fs.writeFileSync(
        "./index.js",
        `import TEXT from './text.file'; import OTHER from './other.other'; export default {};`
      );
      fs.writeFileSync("./text.file", "SOME TEXT CONTENT");
      fs.writeFileSync("./other.other", "SOME OTHER TEXT CONTENT");

      // We throw an error when we come across a file that matched a rule
      // but was skipped because of fallthrough = false
      let err: Error | undefined;
      try {
        await runWrangler("publish index.js");
      } catch (e) {
        err = e as Error;
      }
      expect(err?.message).toMatch(
        `The file ./other.other matched a module rule in your configuration ({"type":"Text","globs":["**/*.other"]}), but was ignored because a previous rule with the same type was not marked as \`fallthrough = true\`.`
      );
      // and the warnings because fallthrough was not explicitly set
      expect(std.warn).toMatchInlineSnapshot(`
        "The module rule at position 1 ({\\"type\\":\\"Text\\",\\"globs\\":[\\"**/*.other\\"]}) has the same type as a previous rule (at position 0, {\\"type\\":\\"Text\\",\\"globs\\":[\\"**/*.file\\"]}). This rule will be ignored. To the previous rule, add \`fallthrough = true\` to allow this one to also be used, or \`fallthrough = false\` to silence this warning.
        The default module rule {\\"type\\":\\"Text\\",\\"globs\\":[\\"**/*.txt\\",\\"**/*.html\\"]} has the same type as a previous rule (at position 0, {\\"type\\":\\"Text\\",\\"globs\\":[\\"**/*.file\\"]}). This rule will be ignored. To the previous rule, add \`fallthrough = true\` to allow the default one to also be used, or \`fallthrough = false\` to silence this warning."
      `);
    });

    describe("inject process.env.NODE_ENV", () => {
      let actualProcessEnvNodeEnv: string | undefined;
      beforeEach(() => {
        actualProcessEnvNodeEnv = process.env.NODE_ENV;
        process.env.NODE_ENV = "some-node-env";
      });
      afterEach(() => {
        process.env.NODE_ENV = actualProcessEnvNodeEnv;
      });
      it("should replace `process.env.NODE_ENV` in scripts", async () => {
        writeWranglerToml();
        fs.writeFileSync(
          "./index.js",
          `export default {
            fetch(){
              return new Response(process.env.NODE_ENV);
            }
          }`
        );
        mockSubDomainRequest();
        mockUploadWorkerRequest({
          expectedEntry: `return new Response("some-node-env");`,
        });
        await runWrangler("publish index.js");
        expect(std.out).toMatchInlineSnapshot(`
          "Uploaded test-name (TIMINGS)
          Published test-name (TIMINGS)
            test-name.test-sub-domain.workers.dev"
        `);
        expect(std.err).toMatchInlineSnapshot(`""`);
        expect(std.warn).toMatchInlineSnapshot(`""`);
      });
    });
  });

  describe("legacy module specifiers", () => {
    it("should work with legacy module specifiers, with a deprecation warning (1)", async () => {
      writeWranglerToml({
        rules: [{ type: "Text", globs: ["**/*.file"], fallthrough: false }],
      });
      fs.writeFileSync(
        "./index.js",
        `import TEXT from 'text.file'; export default {};`
      );
      fs.writeFileSync("./text.file", "SOME TEXT CONTENT");
      mockSubDomainRequest();
      mockUploadWorkerRequest({
        expectedModules: {
          "./2d91d1c4dd6e57d4f5432187ab7c25f45a8973f0-text.file":
            "SOME TEXT CONTENT",
        },
      });
      await runWrangler("publish index.js");
      expect(std.out).toMatchInlineSnapshot(`
        "Uploaded test-name (TIMINGS)
        Published test-name (TIMINGS)
          test-name.test-sub-domain.workers.dev"
      `);
      expect(std.err).toMatchInlineSnapshot(`""`);
      expect(std.warn).toMatchInlineSnapshot(
        `"Deprecation warning: detected a legacy module import in \\"./index.js\\". This will stop working in the future. Replace references to \\"text.file\\" with \\"./text.file\\";"`
      );
    });
  });

  it("should work with legacy module specifiers, with a deprecation warning (2)", async () => {
    writeWranglerToml();
    fs.writeFileSync(
      "./index.js",
      `import WASM from 'index.wasm'; export default {};`
    );
    fs.writeFileSync("./index.wasm", "SOME WASM CONTENT");
    mockSubDomainRequest();
    mockUploadWorkerRequest({
      expectedModules: {
        "./94b240d0d692281e6467aa42043986e5c7eea034-index.wasm":
          "SOME WASM CONTENT",
      },
    });
    await runWrangler("publish index.js");
    expect(std.out).toMatchInlineSnapshot(`
      "Uploaded test-name (TIMINGS)
      Published test-name (TIMINGS)
        test-name.test-sub-domain.workers.dev"
    `);
    expect(std.err).toMatchInlineSnapshot(`""`);
    expect(std.warn).toMatchInlineSnapshot(
      `"Deprecation warning: detected a legacy module import in \\"./index.js\\". This will stop working in the future. Replace references to \\"index.wasm\\" with \\"./index.wasm\\";"`
    );
  });

  it("should not match regular module specifiers when there aren't any possible legacy module matches", async () => {
    // see https://github.com/cloudflare/wrangler2/issues/655 for bug details

    fs.writeFileSync(
      "./index.js",
      `import inner from './inner/index.js'; export default {};`
    );
    fs.mkdirSync("./inner", { recursive: true });
    fs.writeFileSync("./inner/index.js", `export default 123`);
    mockSubDomainRequest();
    mockUploadWorkerRequest();

    await runWrangler(
      "publish index.js --compatibility-date 2022-03-17 --name test-name"
    );
    expect(std.out).toMatchInlineSnapshot(`
      "Uploaded test-name (TIMINGS)
      Published test-name (TIMINGS)
        test-name.test-sub-domain.workers.dev"
    `);
    expect(std.err).toMatchInlineSnapshot(`""`);
    expect(std.warn).toMatchInlineSnapshot(`""`);
  });
});

/** Write a mock Worker script to disk. */
function writeWorkerSource({
  basePath = ".",
  format = "js",
  type = "esm",
}: {
  basePath?: string;
  format?: "js" | "ts" | "jsx" | "tsx" | "mjs";
  type?: "esm" | "sw";
} = {}) {
  if (basePath !== ".") {
    fs.mkdirSync(basePath, { recursive: true });
  }
  fs.writeFileSync(
    `${basePath}/index.${format}`,
    type === "esm"
      ? `import { foo } from "./another";
      export default {
        async fetch(request) {
          return new Response('Hello' + foo);
        },
      };`
      : `import { foo } from "./another";
      addEventListener('fetch', event => {
        event.respondWith(new Response('Hello' + foo));
      })`
  );
  fs.writeFileSync(`${basePath}/another.${format}`, `export const foo = 100;`);
}

/** Write mock assets to the file system so they can be uploaded. */
function writeAssets(assets: { filePath: string; content: string }[]) {
  for (const asset of assets) {
    fs.mkdirSync(path.dirname(asset.filePath), { recursive: true });
    fs.writeFileSync(asset.filePath, asset.content);
  }
}

/** Create a mock handler for the request to upload a worker script. */
function mockUploadWorkerRequest({
  available_on_subdomain = true,
  expectedEntry,
  expectedType = "esm",
  expectedBindings,
  expectedModules = {},
  expectedCompatibilityDate,
  expectedCompatibilityFlags,
  env = undefined,
  legacyEnv = false,
}: {
  available_on_subdomain?: boolean;
  expectedEntry?: string;
  expectedType?: "esm" | "sw";
  expectedBindings?: unknown;
  expectedModules?: Record<string, string>;
  expectedCompatibilityDate?: string;
  expectedCompatibilityFlags?: string[];
  env?: string;
  legacyEnv?: boolean;
} = {}) {
  setMockResponse(
    env && !legacyEnv
      ? "/accounts/:accountId/workers/services/:scriptName/environments/:envName"
      : "/accounts/:accountId/workers/scripts/:scriptName",
    "PUT",
    async ([_url, accountId, scriptName, envName], { body }, queryParams) => {
      expect(accountId).toEqual("some-account-id");
      expect(scriptName).toEqual(
        legacyEnv && env ? `test-name-${env}` : "test-name"
      );
      if (!legacyEnv) {
        expect(envName).toEqual(env);
      }
      expect(queryParams.get("available_on_subdomain")).toEqual("true");
      const formBody = body as FormData;
      if (expectedEntry !== undefined) {
        expect(await (formBody.get("index.js") as File).text()).toMatch(
          expectedEntry
        );
      }
      const metadata = JSON.parse(
        formBody.get("metadata") as string
      ) as WorkerMetadata;
      if (expectedType === "esm") {
        expect(metadata.main_module).toEqual("index.js");
      } else {
        expect(metadata.body_part).toEqual("index.js");
      }
      if (expectedBindings !== undefined) {
        expect(metadata.bindings).toEqual(expectedBindings);
      }
      if (expectedCompatibilityDate !== undefined) {
        expect(metadata.compatibility_date).toEqual(expectedCompatibilityDate);
      }
      if (expectedCompatibilityFlags !== undefined) {
        expect(metadata.compatibility_flags).toEqual(
          expectedCompatibilityFlags
        );
      }
      for (const [name, content] of Object.entries(expectedModules)) {
        expect(await (formBody.get(name) as File).text()).toEqual(content);
      }

      return { available_on_subdomain };
    }
  );
}

/** Create a mock handler for the request to get the account's subdomain. */
function mockSubDomainRequest(
  subdomain = "test-sub-domain",
  registeredWorkersDev = true
) {
  if (registeredWorkersDev) {
    setMockResponse("/accounts/:accountId/workers/subdomain", "GET", () => {
      return { subdomain };
    });
  } else {
    setMockRawResponse("/accounts/:accountId/workers/subdomain", "GET", () => {
      return createFetchResult(null, false, [
        { code: 10007, message: "haven't registered workers.dev" },
      ]);
    });
  }
}

/** Create a mock handler to toggle a <script>.<user>.workers.dev subdomain */
function mockUpdateWorkerRequest({
  env,
  enabled,
  legacyEnv = false,
}: {
  enabled: boolean;
  env?: string | undefined;
  legacyEnv?: boolean | undefined;
}) {
  const requests = { count: 0 };
  const servicesOrScripts = env && !legacyEnv ? "services" : "scripts";
  const environment = env && !legacyEnv ? "/environments/:envName" : "";
  setMockResponse(
    `/accounts/:accountId/workers/${servicesOrScripts}/:scriptName${environment}/subdomain`,
    "POST",
    ([_url, accountId, scriptName, envName], { body }) => {
      expect(accountId).toEqual("some-account-id");
      expect(scriptName).toEqual(
        legacyEnv && env ? `test-name-${env}` : "test-name"
      );
      if (!legacyEnv) {
        expect(envName).toEqual(env);
      }
      expect(JSON.parse(body as string)).toEqual({ enabled });
      return null;
    }
  );
  return requests;
}

function mockPublishRoutesRequest({
  routes,
  env = undefined,
  legacyEnv = false,
}: {
  routes: string[];
  env?: string | undefined;
  legacyEnv?: boolean | undefined;
}) {
  const servicesOrScripts = env && !legacyEnv ? "services" : "scripts";
  const environment = env && !legacyEnv ? "/environments/:envName" : "";

  setMockResponse(
    `/accounts/:accountId/workers/${servicesOrScripts}/:scriptName${environment}/routes`,
    "PUT",
    ([_url, accountId, scriptName, envName], { body }) => {
      expect(accountId).toEqual("some-account-id");
      expect(scriptName).toEqual(
        legacyEnv && env ? `test-name-${env}` : "test-name"
      );
      if (!legacyEnv) {
        expect(envName).toEqual(env);
      }

      expect(JSON.parse(body as string)).toEqual(
        routes.map((pattern) => ({ pattern }))
      );
      return null;
    }
  );
}

/** Create a mock handler for the request to get a list of all KV namespaces. */
function mockListKVNamespacesRequest(...namespaces: KVNamespaceInfo[]) {
  setMockResponse(
    "/accounts/:accountId/storage/kv/namespaces",
    "GET",
    ([_url, accountId]) => {
      expect(accountId).toEqual("some-account-id");
      return namespaces;
    }
  );
}

/** Create a mock handler for the request that tries to do a bulk upload of assets to a KV namespace. */
function mockUploadAssetsToKVRequest(
  expectedNamespaceId: string,
  assets: {
    filePath: string;
    content: string;
    expiration?: number;
    expiration_ttl?: number;
  }[]
) {
  setMockResponse(
    "/accounts/:accountId/storage/kv/namespaces/:namespaceId/bulk",
    "PUT",
    ([_url, accountId, namespaceId], { body }) => {
      expect(accountId).toEqual("some-account-id");
      expect(namespaceId).toEqual(expectedNamespaceId);
      const uploads = JSON.parse(body as string);
      expect(assets.length).toEqual(uploads.length);
      for (let i = 0; i < uploads.length; i++) {
        const asset = assets[i];
        const upload = uploads[i];
        // The asset key consists of:
        // - the basename of the filepath
        // - some hash value
        // - the extension
        const keyMatcher = new RegExp(
          "^" +
            asset.filePath
              .replace(/(\.[^.]+)$/, ".[a-z0-9]+$1")
              .replace(/\./g, "\\.")
        );
        expect(upload.key).toMatch(keyMatcher);
        // The asset value is base64 encoded.
        expect(upload.base64).toBe(true);
        expect(Buffer.from(upload.value, "base64").toString()).toEqual(
          asset.content
        );
        expect(upload.expiration).toEqual(asset.expiration);
        expect(upload.expiration_ttl).toEqual(asset.expiration_ttl);
      }
      return null;
    }
  );
}

/** Create a mock handler for thr request that does a bulk delete of unused assets */
function mockDeleteUnusedAssetsRequest(
  expectedNamespaceId: string,
  assets: string[]
) {
  setMockResponse(
    "/accounts/:accountId/storage/kv/namespaces/:namespaceId/bulk",
    "DELETE",
    ([_url, accountId, namespaceId], { body }) => {
      expect(accountId).toEqual("some-account-id");
      expect(namespaceId).toEqual(expectedNamespaceId);
      const deletes = JSON.parse(body as string);
      expect(assets).toEqual(deletes);
      return null;
    }
  );
}
